{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#65AE11;\">多 GPU</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CUDA 可在单一主机上同时管理多部 GPU 设备。本节您将学习如何执行此操作。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#65AE11;\">目标</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "完成本节内容的学习后，您将能理解并使用 CUDA 语法执行如下操作：\n",
    "\n",
    "* 获取您的应用程序可使用的 GPU 的数量\n",
    "* 激活任意可用的 GPU\n",
    "* 在多个 GPU 上分配显存\n",
    "* 在多个 GPU 上传入和转出显存数据\n",
    "* 在多个 GPU 上启动核函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#65AE11;\">演示</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行以下单元以加载本节的视频演示。看完演示后，继续完成此 Notebook 余下的部分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<video width=\"800\" controls>\n",
    "  <source src=\"https://dli-lms.s3.us-east-1.amazonaws.com/assets/s-ac-02-v1-zh/05-multiple-gpus-01.mp4\" type=\"video/mp4\">\n",
    "  Your browser does not support HTML video.\n",
    "</video>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#65AE11;\">获取多个 GPU 的相关信息</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如要以运行程序的方式得出可用 GPU 的数量，请使用 `cudaGetDeviceCount`："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```c\n",
    "int num_gpus;\n",
    "cudaGetDeviceCount(&num_gpus);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如要以运行程序的方式得到当前处于活动状态的 GPU，请使用 `cudaGetDevice`："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```c\n",
    "int device;\n",
    "cudaGetDevice(&device); // `device` is now a 0-based index of the current GPU.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#65AE11;\">设置当前的 GPU</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于每个主机线程，每次只有一个 GPU 设备处于活动状态。如要将特定的 GPU 设置为活动状态，请使用 `cudaSetDevice` 以及所需 GPU 的索引（从 0 开始）："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```c\n",
    "cudaSetDevice(0);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#65AE11;\">遍历可用的 GPU</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一种常见模式为遍历可用的 GPU，并为每个 GPU 执行相应的操作："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```c\n",
    "int num_gpus;\n",
    "cudaGetDeviceCount(&num_gpus);\n",
    "\n",
    "for (int gpu = 0; gpu < num_gpus; gpu++) {\n",
    "\n",
    "    cudaSetDevice(gpu);\n",
    "    \n",
    "    // Perform operations for this GPU.\n",
    "}    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#65AE11;\">为多个 GPU 执行数据分块</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在使用多个非默认流执行复制和计算重叠时，多个 GPU 中的每个 GPU 都可处理一个数据块。我们将创建和利用数据指针数组为每个可用的 GPU 分配显存："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```c\n",
    "const int num_gpus;\n",
    "cudaGetDeviceCount(&num_gpus);\n",
    "\n",
    "const uint64_t num_entries = 1UL << 26;\n",
    "const uint64_t chunk_size = sdiv(num_entries, num_gpus);\n",
    "\n",
    "uint64_t *data_gpu[num_gpus]; // One pointer for each GPU.\n",
    "\n",
    "for (int gpu = 0; gpu < num_gpus; gpu++) {\n",
    "\n",
    "    cudaSetDevice(gpu);\n",
    "\n",
    "    const uint64_t lower = chunk_size*gpu;\n",
    "    const uint64_t upper = min(lower+chunk_size, num_entries);\n",
    "    const uint64_t width = upper-lower;\n",
    "\n",
    "    cudaMalloc(&data_gpu[gpu], sizeof(uint64_t)*width); // Allocate chunk of data for current GPU.\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#65AE11;\">为多个 GPU 复制数据</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过使用相同的遍历和分块技术，我们可在多个 GPU 上传入和传出数据："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```c\n",
    "// ...Assume data has been allocated on host and for each GPU\n",
    "\n",
    "for (int gpu = 0; gpu < num_gpus; gpu++) {\n",
    "\n",
    "    cudaSetDevice(gpu);\n",
    "\n",
    "    const uint64_t lower = chunk_size*gpu;\n",
    "    const uint64_t upper = min(lower+chunk_size, num_entries);\n",
    "    const uint64_t width = upper-lower;\n",
    "\n",
    "    // Note use of `cudaMemcpy` and not `cudaMemcpyAsync` since we are not\n",
    "    // presently using non-default streams.\n",
    "    cudaMemcpy(data_gpu[gpu], data_cpu+lower, \n",
    "           sizeof(uint64_t)*width, cudaMemcpyHostToDevice); // ...or cudaMemcpyDeviceToHost\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#65AE11;\">为多个 GPU 启动核函数</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过使用相同的遍历和分块技术，我们可在多个 GPU 上启动核函数以处理数据块："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```c\n",
    "// ...Assume data has been allocated on host and for each GPU\n",
    "\n",
    "for (int gpu = 0; gpu < num_gpus; gpu++) {\n",
    "\n",
    "    cudaSetDevice(gpu);\n",
    "\n",
    "    const uint64_t lower = chunk_size*gpu;\n",
    "    const uint64_t upper = min(lower+chunk_size, num_entries);\n",
    "    const uint64_t width = upper-lower;\n",
    "\n",
    "    kernel<<<grid, block>>>(data_gpu[gpu], width); // Pass chunk of data for current GPU to work on.\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#65AE11;\">知识检查</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请回答下列问题，确认您已了解本节的主要目标。您可以通过单击问题下方的`...`单元来显示每个问题的答案。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**哪个 CUDA 运行时调用可以得到可用 GPU 的数量？**\n",
    "\n",
    "1. `cudaGetDevice`\n",
    "2. `cudaSetDevice`\n",
    "3. `cudaGetDeviceCount`\n",
    "4. `cudaGetDeviceProperties`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "**答案：3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**哪个 CUDA 运行时调用可选择当前让某个 GPU 处于活动状态？**\n",
    "\n",
    "1. `cudaGetDevice`\n",
    "2. `cudaSetDevice`\n",
    "3. `cudaGetDeviceCount`\n",
    "4. `cudaGetDeviceProperties`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "**答案：2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**单 GPU 系统上的 GPU 索引是多少？**\n",
    "\n",
    "1. 1\n",
    "2. 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "**答案：2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#65AE11;\">下一步</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在你已熟悉有关使用多个 GPU 的语法和技术，下一节中，你将运用对所学内容的理解重构基准密码应用，以使用多个 GPU。\n",
    "\n",
    "请继续学习下一节：[*使用多个 GPU*](../06_Exercise_MGPU/Exercise_MGPU.ipynb)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#65AE11;\">可选的进一步学习的材料</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下内容供有时间和兴趣的学生就与本课程相关的主题进一步学习。\n",
    "\n",
    "* 在上面，我们使用[深度优先](https://www.geeksforgeeks.org/difference-between-bfs-and-dfs/#:~:text=BFS(Breadth%20First%20Search)%20uses,edges%20from%20a%20source%20vertex.)的方法将一部分工作传递给每个GPU。在某些情况下，尤其是在数据量极高的情况下，使用宽度优先的方法可能更有意义。这种方法上的改变并不是需要额外的CUDA知识。不过，此[stack overflow的回答](https://stackoverflow.com/questions/11673154/concurrency-in-cuda-multi-gpu-executions)提供了一些使用深度优先和宽度优先方法的CUDA代码示例。\n",
    "* 多个GPU之间进行对等内存传输，以及在多个节点上使用多个GPU，两者均不在本课程的讨论范围之内。 [此超级计算会议演示文稿](https://www.nvidia.com/docs/IO/116711/sc11-multi-gpu.pdf)将为您探索这些主题（以及更多）提供一个很好的起点。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
