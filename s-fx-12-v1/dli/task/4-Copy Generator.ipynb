{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c461f5a5-f293-4410-82a5-ba49d3c6c9d4",
   "metadata": {},
   "source": [
    "<center><img src=\"/files/images/DLI_Header.png\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af339990-a99d-484a-86e1-68cd5f284f16",
   "metadata": {},
   "source": [
    "# Star Bikes 营销文案生成器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f473856a-e4a0-40f2-9ee5-2aed42e2d0e1",
   "metadata": {},
   "source": [
    "在此 notebook 中，您将构建一个 AI 驱动的营销文案撰写器，来执行一些生成任务。您将学习如何编辑模型的**系统消息**（system message），以定义其响应。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fcef33-9af0-4fbd-a95d-bafcd4345ce4",
   "metadata": {},
   "source": [
    "## 学习目标"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be50e4b0-e588-4f97-8d60-6860827aa997",
   "metadata": {},
   "source": [
    "完成此 notebook 后，您将能够：\n",
    "* 使用 LLaMA-2 执行各种**文本生成**任务。\n",
    "* 使用**系统上下文**为 LLaMA-2 模型定义其首要（overarching）角色。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c59404a-c8b1-4227-a3f2-da0eeffe3b7d",
   "metadata": {},
   "source": [
    "## 视频教程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d86f5e-b354-4742-b771-4c0f2ede7cb3",
   "metadata": {},
   "source": [
    "执行以下单元以加载此 notebook 的视频教程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5783c7-0fa8-4787-a3de-93b40aa74dc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " from IPython.display import HTML\n",
    "\n",
    "video_url = \"https://d36m44n9vdbmda.cloudfront.net/assets/s-fx-12-v1/v2/04-copy.mp4\"\n",
    "\n",
    "video_html = f\"\"\"\n",
    "<video controls width=\"640\" height=\"360\">\n",
    "    <source src=\"{video_url}\" type=\"video/mp4\">\n",
    "    Your browser does not support the video tag.\n",
    "</video>\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(video_html))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d7f877-c256-4808-b29f-0165f66870b7",
   "metadata": {},
   "source": [
    "## 创建 LLaMA-2 工作流"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4939afbd-23ca-4db8-b12b-209c224ee4ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "model = \"TheBloke/Llama-2-13B-chat-GPTQ\"\n",
    "# model = \"TheBloke/Llama-2-7B-chat-GPTQ\"\n",
    "\n",
    "llama_pipe = pipeline(\"text-generation\", model=model, device_map=\"auto\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682be0d3-4ba9-4a89-9db3-f8ec4b311185",
   "metadata": {},
   "source": [
    "## 辅助函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6d6710-8530-44e3-b7d8-0899e948bada",
   "metadata": {},
   "source": [
    "在此 notebook 中，我们将使用以下函数与 LLM 交互。可以先大概看一眼，后面会详细介绍。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408e3628-7fee-4202-8734-2e8da3adf574",
   "metadata": {},
   "source": [
    "### 生成模型响应"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda46556-8b36-407d-94d0-1483cb065e9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate(prompt, max_length=1024, pipe=llama_pipe, **kwargs):\n",
    "    \"\"\"\n",
    "    Generates a response to the given prompt using a specified language model pipeline.\n",
    "\n",
    "    This function takes a prompt and passes it to a language model pipeline, such as LLaMA, \n",
    "    to generate a text response. The function is designed to allow customization of the \n",
    "    generation process through various parameters and keyword arguments.\n",
    "\n",
    "    Parameters:\n",
    "    - prompt (str): The input text prompt to generate a response for.\n",
    "    - max_length (int): The maximum length of the generated response. Default is 1024 tokens.\n",
    "    - pipe (callable): The language model pipeline function used for generation. Default is llama_pipe.\n",
    "    - **kwargs: Additional keyword arguments that are passed to the pipeline function.\n",
    "\n",
    "    Returns:\n",
    "    - str: The generated text response from the model, trimmed of leading and trailing whitespace.\n",
    "\n",
    "    Example usage:\n",
    "    ```\n",
    "    prompt_text = \"Explain the theory of relativity.\"\n",
    "    response = generate(prompt_text, max_length=512, pipe=my_custom_pipeline, temperature=0.7)\n",
    "    print(response)\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    def_kwargs = dict(return_full_text=False, return_dict=False)\n",
    "    response = pipe(prompt.strip(), max_length=max_length, **kwargs, **def_kwargs)\n",
    "    return response[0]['generated_text'].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e07bb2-1cee-4785-99b9-b67fe2fb5a5d",
   "metadata": {},
   "source": [
    "### 构造提示词，包括可选的系统上下文和/或示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4c9a4f-570b-4de7-b46c-8aba8a571edc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def construct_prompt_with_context(main_prompt, system_context=\"\", conversation_examples=[]):\n",
    "    \"\"\"\n",
    "    Constructs a complete structured prompt for a language model, including optional system context and conversation examples.\n",
    "\n",
    "    This function compiles a prompt that can be directly used for generating responses from a language model. \n",
    "    It creates a structured format that begins with an optional system context message, appends a series of conversational \n",
    "    examples as prior interactions, and ends with the main user prompt. If no system context or conversation examples are provided,\n",
    "    it will return only the main prompt.\n",
    "\n",
    "    Parameters:\n",
    "    - main_prompt (str): The core question or statement for the language model to respond to.\n",
    "    - system_context (str, optional): Additional context or information about the scenario or environment. Defaults to an empty string.\n",
    "    - conversation_examples (list of tuples, optional): Prior exchanges provided as context, where each tuple contains a user message \n",
    "      and a corresponding agent response. Defaults to an empty list.\n",
    "\n",
    "    Returns:\n",
    "    - str: A string formatted as a complete prompt ready for language model input. If no system context or examples are provided, returns the main prompt.\n",
    "\n",
    "    Example usage:\n",
    "    ```\n",
    "    main_prompt = \"I'm looking to improve my dialogue writing skills for my next short story. Any suggestions?\"\n",
    "    system_context = \"User is an aspiring author seeking to enhance dialogue writing techniques.\"\n",
    "    conversation_examples = [\n",
    "        (\"How can dialogue contribute to character development?\", \"Dialogue should reveal character traits and show personal growth over the story arc.\"),\n",
    "        (\"What are some common pitfalls in writing dialogue?\", \"Avoid exposition dumps in dialogue and make sure each character's voice is distinct.\")\n",
    "    ]\n",
    "\n",
    "    full_prompt = construct_prompt_with_context(main_prompt, system_context, conversation_examples)\n",
    "    print(full_prompt)\n",
    "    ```\n",
    "    \"\"\"\n",
    "    \n",
    "    # Return the main prompt if no system context or conversation examples are provided\n",
    "    if not system_context and not conversation_examples:\n",
    "        return main_prompt\n",
    "\n",
    "    # Start with the initial part of the prompt including the system context, if provided\n",
    "    full_prompt = f\"<s>[INST] <<SYS>>{system_context}<</SYS>>\\n\" if system_context else \"<s>[INST]\\n\"\n",
    "\n",
    "    # Add each example from the conversation_examples to the prompt\n",
    "    for user_msg, agent_response in conversation_examples:\n",
    "        full_prompt += f\"{user_msg} [/INST] {agent_response} </s><s>[INST]\"\n",
    "\n",
    "    # Add the main user prompt at the end\n",
    "    full_prompt += f\"{main_prompt} [/INST]\"\n",
    "\n",
    "    return full_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47884189-00e6-4c0d-8e5c-edf41411f088",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Star Bikes 数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a27cac-12ac-4f7c-8065-bb541eb82394",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bikes = [\n",
    "    {\n",
    "        \"model\": \"Galaxy Rider\",\n",
    "        \"type\": \"Mountain\",\n",
    "        \"features\": {\n",
    "            \"frame\": \"Aluminum alloy\",\n",
    "            \"gears\": \"21-speed Shimano\",\n",
    "            \"brakes\": \"Hydraulic disc\",\n",
    "            \"tires\": \"27.5-inch all-terrain\",\n",
    "            \"suspension\": \"Full, adjustable\",\n",
    "            \"color\": \"Matte black with green accents\"\n",
    "        },\n",
    "        \"usps\": [\"Lightweight frame\", \"Quick gear shift\", \"Durable tires\"],\n",
    "        \"price\": 799.95,\n",
    "        \"internal_id\": \"GR2321\",\n",
    "        \"weight\": \"15.3 kg\",\n",
    "        \"manufacturer_location\": \"Taiwan\"\n",
    "    },\n",
    "    {\n",
    "        \"model\": \"Nebula Navigator\",\n",
    "        \"type\": \"Hybrid\",\n",
    "        \"features\": {\n",
    "            \"frame\": \"Carbon fiber\",\n",
    "            \"gears\": \"18-speed Nexus\",\n",
    "            \"brakes\": \"Mechanical disc\",\n",
    "            \"tires\": \"26-inch city slick\",\n",
    "            \"suspension\": \"Front only\",\n",
    "            \"color\": \"Glossy white\"\n",
    "        },\n",
    "        \"usps\": [\"Sleek design\", \"Efficient on both roads and trails\", \"Ultra-lightweight\"],\n",
    "        \"price\": 649.99,\n",
    "        \"internal_id\": \"NN4120\",\n",
    "        \"weight\": \"13.5 kg\",\n",
    "        \"manufacturer_location\": \"Germany\"\n",
    "    },\n",
    "    {\n",
    "        \"model\": \"Cosmic Comet\",\n",
    "        \"type\": \"Road\",\n",
    "        \"features\": {\n",
    "            \"frame\": \"Titanium\",\n",
    "            \"gears\": \"24-speed Campagnolo\",\n",
    "            \"brakes\": \"Rim brakes\",\n",
    "            \"tires\": \"700C road\",\n",
    "            \"suspension\": \"None\",\n",
    "            \"color\": \"Metallic blue\"\n",
    "        },\n",
    "        \"usps\": [\"Super aerodynamic\", \"High-speed performance\", \"Professional-grade components\"],\n",
    "        \"price\": 1199.50,\n",
    "        \"internal_id\": \"CC5678\",\n",
    "        \"weight\": \"11 kg\",\n",
    "        \"manufacturer_location\": \"Italy\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a4dc85-0f8b-4bb1-a41c-f9d6ee3159b9",
   "metadata": {},
   "source": [
    "## 完整的 LLaMA-2 提示模板"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc46532c-53c4-462f-b8dd-69923319d6da",
   "metadata": {},
   "source": [
    "在上一个 notebook 中，我们利用 LLaMA-2 **提示模板**来进行**少样本学习**，但也提到了我们使用的是略作修改的提示模板。具体来说，省略了被称为**系统消息**的用户消息、或者说是系统上下文或系统提示词（我们将交替使用这些术语）。下方是完整的 LLaMA-2 提示模板，包括了**系统上下文**。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d27794-a34e-4224-a034-072141a3c94a",
   "metadata": {
    "tags": []
   },
   "source": [
    "```python\n",
    "<s>[INST] <<SYS>>\n",
    "{{ system_context }}\n",
    "<</SYS>>\n",
    "\n",
    "{{ user_msg_1 }} [/INST] {{ model_answer_1 }} </s>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a99577-670c-4dc2-863e-ea76b411c7ef",
   "metadata": {},
   "source": [
    "**系统上下文**是用户/模型交互中用户侧的一部分，在 `<<SYS>>` 和 `<</SYS>>` 标签之间。**系统上下文**是将 AI 模型的响应导向特定框架或任务理解的线索。\n",
    "\n",
    "关于**系统上下文**中应该写些什么内容，并没有短平快的规定。但我们可以将其视为对模型角色的设定，或是应作用到其所有响应的模式。\n",
    "\n",
    "这是 LLaMA-2 聊天模型的默认**系统消息**，是指令微调期间用的："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6928fa1-d99a-47af-a69e-23d3c2bac996",
   "metadata": {
    "tags": []
   },
   "source": [
    ">你是一个很有帮助、礼貌和诚实的助手。在安全的情况下，始终尽可能的提供帮助。你的回答不应包含任何有害、不道德、种族主义、性别主义、有毒、危险或违法的内容。请确保您的回答不带有社会偏见，并且是积极的。\\\n",
    ">如果一个问题没有任何意义，或与事实相悖，请进行解释而不是给出不正确的回复。如果你不知道问题的答案，请不要给出错误的信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9428f44-b399-4280-9011-68b08bc251e7",
   "metadata": {},
   "source": [
    "## 设置系统上下文"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a8cb5e-1a77-4156-9b3e-bbfb3eed1b1c",
   "metadata": {},
   "source": [
    "下面的 `construct_prompt_with_context` 函数将帮助我们用 LLaMA-2 **提示模板**构建更新了**系统消息**的提示词。如果我们愿意，该函数还允许我们通过传递示例交互的二元组列表来执行**少样本学习**，跟上一节一样。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798d623e-8ff3-4142-8d63-93848c5a82c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def construct_prompt_with_context(main_prompt, system_context=\"\", conversation_examples=[]):\n",
    "    \"\"\"\n",
    "    Constructs a complete structured prompt for a language model, including optional system context and conversation examples.\n",
    "\n",
    "    This function compiles a prompt that can be directly used for generating responses from a language model. \n",
    "    It creates a structured format that begins with an optional system context message, appends a series of conversational \n",
    "    examples as prior interactions, and ends with the main user prompt. If no system context or conversation examples are provided,\n",
    "    it will return only the main prompt.\n",
    "\n",
    "    Parameters:\n",
    "    - main_prompt (str): The core question or statement for the language model to respond to.\n",
    "    - system_context (str, optional): Additional context or information about the scenario or environment. Defaults to an empty string.\n",
    "    - conversation_examples (list of tuples, optional): Prior exchanges provided as context, where each tuple contains a user message \n",
    "      and a corresponding agent response. Defaults to an empty list.\n",
    "\n",
    "    Returns:\n",
    "    - str: A string formatted as a complete prompt ready for language model input. If no system context or examples are provided, returns the main prompt.\n",
    "\n",
    "    Example usage:\n",
    "    ```\n",
    "    main_prompt = \"I'm looking to improve my dialogue writing skills for my next short story. Any suggestions?\"\n",
    "    system_context = \"User is an aspiring author seeking to enhance dialogue writing techniques.\"\n",
    "    conversation_examples = [\n",
    "        (\"How can dialogue contribute to character development?\", \"Dialogue should reveal character traits and show personal growth over the story arc.\"),\n",
    "        (\"What are some common pitfalls in writing dialogue?\", \"Avoid exposition dumps in dialogue and make sure each character's voice is distinct.\")\n",
    "    ]\n",
    "\n",
    "    full_prompt = construct_prompt_with_context(main_prompt, system_context, conversation_examples)\n",
    "    print(full_prompt)\n",
    "    ```\n",
    "    \"\"\"\n",
    "    \n",
    "    # Return the main prompt if no system context or conversation examples are provided\n",
    "    if not system_context and not conversation_examples:\n",
    "        return main_prompt\n",
    "\n",
    "    # Start with the initial part of the prompt including the system context, if provided\n",
    "    full_prompt = f\"<s>[INST] <<SYS>>{system_context}<</SYS>>\\n\" if system_context else \"<s>[INST]\\n\"\n",
    "\n",
    "    # Add each example from the conversation_examples to the prompt\n",
    "    for user_msg, agent_response in conversation_examples:\n",
    "        full_prompt += f\"{user_msg} [/INST] {agent_response} </s><s>[INST]\"\n",
    "\n",
    "    # Add the main user prompt at the end\n",
    "    full_prompt += f\"{main_prompt} [/INST]\"\n",
    "\n",
    "    return full_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249e919d-7f72-4aa6-9234-b5fd7c8baefa",
   "metadata": {},
   "source": [
    "## Star Bikes 营销文案生成器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cb5d20-19bd-4571-b34e-68e8155dad6e",
   "metadata": {},
   "source": [
    "让我们将 LLaMA-2 用作营销文案生成器。对于这个任务，我们将提供给模型关于 Star Bikes 自行车的相关规格。`bikes` 的定义可以在上方的 *Star Bikes 数据* 中查看。\n",
    "\n",
    "我们先从一个简单的提示词开始。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cc4a56-c930-48cd-8be7-532bcb4162ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Write marketing copy for the following bicycle: {bikes[0]}\n",
    "\"\"\"\n",
    "\n",
    "print(generate(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e9821b-de8d-4081-b208-9d1ee791d98d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4724a9e-1266-4bd8-b0c7-9c29212a4c64",
   "metadata": {},
   "source": [
    "看起来还不错，可以以此为基础继续迭代提示词来优化模型的响应。但假设我们希望模型充当营销文案撰写者，来编写多种格式的文案，那就可以为模型提供**系统上下文**让它知道自己的角色。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a54a453-585a-4e67-9133-e0fb55cb8873",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "system_context = f\"\"\"\n",
    "You are a marketing copy writer for Star Bikes.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "{bikes[0]}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4902c7bb-db2a-46c3-a555-a433c57bbea9",
   "metadata": {},
   "source": [
    "使用我们提供的 `construct_prompt_with_context` 函数可以创建一个按 LLaMA-2 提示模板要求的带有**系统上下文**的提示词。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767b7503-8a06-4c50-b9b2-17d2b275daa3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_with_system_context = construct_prompt_with_context(prompt, system_context)\n",
    "print(prompt_with_system_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7609f10-f4a4-4d50-9360-d218909c8185",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c674e694-8fe3-47bf-b123-5623a81f0dc2",
   "metadata": {},
   "source": [
    "使用带有**系统上下文**的提示词，现在看看模型会给我们什么样的响应。值得一提的是，我们的主 `prompt`（见上文）没有提供关于模型要做什么的指令。我们仅依赖**系统上下文**来指导模型的行为。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b681bc97-63ae-4d37-8f2b-c18977c7b52c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(generate(prompt_with_system_context))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decc9717-dd16-4334-9640-61a8d226f059",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53c6b56-90ad-4f8a-8681-5ee828d50065",
   "metadata": {},
   "source": [
    "一点也不赖，现在我们争取让**系统上下文**更**精确**，让模型只生成营销文案，而不要像刚刚的响应开头那样加一句：`Sure! Here's the marketing copy for the Galaxy Rider mountain bike:`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8265b6-06e3-45ed-9969-56a4f7dcf894",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "system_context = f\"\"\"\n",
    "You are a marketing copy writer for Star Bikes. You only write marketing copy and never any \\\n",
    "leading comments or pieces of conversation.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "{bikes[0]}\n",
    "\"\"\"\n",
    "\n",
    "print(generate(construct_prompt_with_context(prompt, system_context)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6261046-d977-4aba-95f2-0c52aa6a36c2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af91df7-ee21-4240-9cd1-5937262c0d92",
   "metadata": {},
   "source": [
    "好像没起什么作用。让我们继续迭代。或许可以尝试告诉模型它是一台机器，这样就不会像人类那样对话了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfd1d32-3e8f-49a6-9a0f-22e2b89fd672",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "system_context = f\"\"\"\n",
    "You are a non-conversant machine that generates marketing copy in 100 words or less. You work for Star Bikes.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "{bikes[0]}\n",
    "\"\"\"\n",
    "\n",
    "print(generate(construct_prompt_with_context(prompt, system_context)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51f6bd0-9162-4035-809b-6fe273737ce6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4c2d4c-ead3-47d4-b6af-0f3b6c375925",
   "metadata": {},
   "source": [
    "好多了！与所有的提示工程一样，开发有效的**系统提示**通常是一个迭代过程。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0347268b-ce78-48f8-a24b-49cf0d3c244f",
   "metadata": {},
   "source": [
    "## 力求简洁"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bf3681-0133-4d33-b632-d4453dd94f83",
   "metadata": {},
   "source": [
    "假设我们希望只得到大约 100 个词的响应，可以通过更新**系统上下文**来反映这一点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a959dda4-4196-425c-954f-75c10ff30545",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "system_context = f\"\"\"\n",
    "You are a non-conversant machine that generates marketing copy in 100 words or less. You work for Star Bikes.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "{bikes[0]}\n",
    "\"\"\"\n",
    "\n",
    "print(generate(construct_prompt_with_context(prompt, system_context)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde70ee8-01da-406e-a6bf-32b51ce522bc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8c36ba-7434-44d6-bb83-517800944c83",
   "metadata": {},
   "source": [
    "非常好。现在的设置看起来很好用，让我们试试剩下的自行车数据："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b75d271-072f-493d-bce2-4f9994b2a844",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for bike in bikes[1:]:\n",
    "    print(generate(construct_prompt_with_context(bike, system_context)))\n",
    "    print(\"\\n-----\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72596c88-4c23-4cd7-addf-1692c28c6c36",
   "metadata": {},
   "source": [
    "## 练习：生成营销电子邮件"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691d517d-65da-4ccf-95ee-a80cbb468544",
   "metadata": {},
   "source": [
    "根据您迄今为止所学的内容，创建一个可以给顾客撰写特定自行车营销邮件的提示词（利用**系统上下文**）。电子邮件应标明收件人的姓名。\n",
    "\n",
    "如果遇到问题，请查看下方的参考答案。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9392c0-bc95-4b03-b372-ba1fa7c25813",
   "metadata": {},
   "source": [
    "### 您的代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b8ee94-39b6-40d0-9621-6452ed715014",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b2ac353-a873-430b-8a10-c93e45419ae5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 参考答案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2256a6e4-fec7-4d4c-80f9-697865ed4e77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "system_context = f\"\"\"\n",
    "You are a non-conversant machine that generates marketing emails in 100 words or less. You work for Star Bikes.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Recipient Name: Stella\n",
    "{bikes[0]}\n",
    "\"\"\"\n",
    "\n",
    "print(generate(construct_prompt_with_context(prompt, system_context)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ada345a-39f1-42d7-a63a-7e97a1317978",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 关键概念回顾"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecc7f33-9e53-4b7d-adc5-54b6f7322206",
   "metadata": {},
   "source": [
    "此 notebook 介绍了以下关键概念：\n",
    "\n",
    "* **系统消息**：指令微调模型提示模板的一部分，允许用户设置模型的角色或配置其总体行为。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfb5f5f-fb8a-458d-8b2d-14164857164d",
   "metadata": {},
   "source": [
    "## 可选的进阶练习"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff817bde-7bbb-4a88-9a0b-887ca533f702",
   "metadata": {},
   "source": [
    "如果您想超出本课程的内容进阶一下，可以试试下面的额外开放式练习。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cf8fdb-7ddc-446e-b530-d25eb8a25069",
   "metadata": {},
   "source": [
    "### 使用 7B 模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc567fb7-8364-4c8c-95a1-0a510036fa0c",
   "metadata": {},
   "source": [
    "在 notebook 顶部，按照下面的代码重启内核后，取消注释以使用 7B 模型，而不是 13B 模型。试试通过提示工程在使用小（更弱）模型的情况下获得满意的结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cbccb1-bc7e-4b72-9f25-37b797095749",
   "metadata": {},
   "source": [
    "### 试验如何得到更好的提示词"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd98e41-ec75-4fc2-b51d-94139083abd8",
   "metadata": {},
   "source": [
    "我们通过对基本提示词进行迭代、编辑系统消息、提供示例（又叫“样本”）来帮助模型提升效果。与其说这是科学，不如说是一门艺术：看看您是否可以通过加强这 3 种改进来获得更好的效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20744407-6de1-4ac3-b08e-dc5e75972cb9",
   "metadata": {},
   "source": [
    "### 创建电子邮件生成工作流"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf2d2a7-dea2-4b9c-a140-80b639e7e0ac",
   "metadata": {},
   "source": [
    "扩展上述练习中的工作，创建一个能给一组收件人分别生成邮件的工作流。除了参考收件人姓名之外，可以试试根据他们之前买过或感兴趣的自行车（无论之前是否发过邮件）来创建与这些细节更相关的电子邮件。\n",
    "\n",
    "您还可以考虑用**少样本学习**以特定方式组织电子邮件。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37acb023-5f07-4bb9-8343-c7e3230deea6",
   "metadata": {
    "tags": []
   },
   "source": [
    "重启内核\n",
    "----\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a8ecaf-b860-487f-8b4d-b4dd358fa06f",
   "metadata": {},
   "source": [
    "为下一个 notebook 释放 GPU 显存，请运行以下单元。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379dc277-e2f2-4ac3-8972-842ad073edb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython import get_ipython\n",
    "\n",
    "get_ipython().kernel.do_shutdown(restart=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
