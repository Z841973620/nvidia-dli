{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79457a5b-a96e-4c87-9cc4-ffbb9cab80a8",
   "metadata": {},
   "source": [
    "<center><img src=\"/files/images/DLI_Header.png\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dc9691-32f3-4ade-98ae-8c3079c4ea8d",
   "metadata": {},
   "source": [
    "# 课程总结"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b2ad9d-b0d6-4a7e-91e3-025c54226e58",
   "metadata": {},
   "source": [
    "恭喜您完成了*使用 LLaMA-2 进行提示工程*课程！我们真诚的希望您能喜欢本课程，并切实的让您更有信心通过各种提示工程技术提高您与 LLM 交互的能力。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cda93c0-20a2-47c2-8676-e21a606c2ee1",
   "metadata": {},
   "source": [
    "## 视频教程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0375bfe8-b3a2-4389-970d-e902b48ce0bd",
   "metadata": {},
   "source": [
    "执行以下单元以加载此 notebook 的视频教程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0936fb-6353-4bca-ad6e-666fbd0f0404",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " from IPython.display import HTML\n",
    "\n",
    "video_url = \"https://d36m44n9vdbmda.cloudfront.net/assets/s-fx-12-v1/v2/08-conclusion.mp4\"\n",
    "\n",
    "video_html = f\"\"\"\n",
    "<video controls width=\"640\" height=\"360\">\n",
    "    <source src=\"{video_url}\" type=\"video/mp4\">\n",
    "    Your browser does not support the video tag.\n",
    "</video>\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(video_html))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f767d1bc-0ca6-4e21-bf9a-90122b3456ec",
   "metadata": {},
   "source": [
    "## 课程回顾"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b09fb9-804e-4a27-b134-141b0d7411a1",
   "metadata": {},
   "source": [
    "您在本课程中学习了很多内容。现在您可以：\n",
    "* **迭代**地创建**具体**的提示词、提供**提示**线索并给模型**“思考时间”**。\n",
    "* 对非结构化文本执行**情感分析**。\n",
    "* 理解 LLaMA-2 **提示模板**及其在**指令微调**中的作用。\n",
    "* 使用**少样本学习**为 LLM 提供有指导性的示例。\n",
    "* 使用 LLM 生成结构化数据供下游任务使用。\n",
    "* 使用**系统上下文**为模型设定一个角色，以执行各种**文本生成**任务。\n",
    "* 使用**采样**和**温度**调控模型输出的随机性。\n",
    "* 用模型构建一个聊天机器人，包括保留对话历史记录的能力。\n",
    "* 创建能够讨论特定任务细节（以数据形式提供）的 **AI 助手**。\n",
    "* 生成**合成数据**。\n",
    "* 在模型的 **token 限制**范围内工作。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6627ddaa-5abe-4669-a3b9-0150948a4bfb",
   "metadata": {},
   "source": [
    "## 下一步"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40b4bf7-15c0-4d6d-95a4-eba36b979623",
   "metadata": {},
   "source": [
    "现在，您已经掌握了一套实用的提示工程技能，以下主题可能会让您感兴趣。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e597140-25ea-4344-8163-402abcbc57da",
   "metadata": {},
   "source": [
    "### LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981c23c3-1243-473d-b957-ed2b3105896f",
   "metadata": {},
   "source": [
    "“[LangChain](https://python.langchain.com/docs/get_started/introduction) 是一个用于开发由大型语言模型驱动的应用程序的框架。”他是免费开源的，并逐渐开发出越来越多的用于配合 LLM 使用的模块和组件。\n",
    "\n",
    "在本课程中，我们有意的直接用 Python 创建辅助函数和类，并以此全面的了解了提示工程的核心实践。但是，LangChain 可以通过为您提供样板代码来加速您未来的工作，能够加速和扩展您在本课程中所学到的技术以及 LLM 的用途。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8293ab0b-2d8f-45cd-b737-74658d310389",
   "metadata": {},
   "source": [
    "### 检索增强生成（RAG）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51d44b6-6c82-45c4-9cf1-c58a91e51a78",
   "metadata": {},
   "source": [
    "在本课程中，我们提到了 LLM 的能力受制于其能处理的 token 数。\n",
    "\n",
    "[检索增强生成（Retrieval-Augmented Generation）](https://research.ibm.com/blog/retrieval-augmented-generation-RAG)（或简称 RAG）允许 LLM 从大型数据库（比如 [FAISS](https://python.langchain.com/docs/integrations/vectorstores/faiss) 这类向量数据库）中检索出相关信息，并以此给出响应。这允许模型“查找”大量信息，而无需在即时上下文（比如提示词）中记住所有信息。\n",
    "\n",
    "RAG 在很大程度上消除了 token 限制对提示工程的约束，还能让模型获取并未在训练集中出现的信息。\n",
    "\n",
    "您可以学习 DLI 的免费课程“[使用 RAG 增强大语言模型入门](https://learn.nvidia.com/courses/course-detail?course_id=course-v1:DLI+S-FX-16+V1-ZH)”来进一步了解 RAG。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebdb27f-ad83-4e37-b929-7ee6c9611f1d",
   "metadata": {},
   "source": [
    "### 参数高效微调（PEFT）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de35cdf-1f8a-423b-a447-8f8d773cb842",
   "metadata": {},
   "source": [
    "本课程中，我们能够通过提示工程来影响模型的行为。但是，提示工程对模型的控制程度是有限的。\n",
    "\n",
    "当多样本学习不足以从 LLM 中激发出我们需要的行为时，无论是由于响应格式还是其正确性需要依赖特定的领域知识，接下来就该尝试执行参数高效微调了。\n",
    "\n",
    "与完整的模型微调相比，PEFT 技术允许使用相对较少的（数百到数千个）训练示例对 LLM 进行特定任务的适应，大幅降低了算力成本。PEFT 是一种无需重新训练整个模型，就可以在特定类型的任务上“启动”的方法。\n",
    "\n",
    "您可以学习 DLI 最新的课程“[高效定制大语言模型 (LLM)](https://www.nvidia.cn/training/instructor-led-workshops/efficient-large-language-model-customization/)”来深入了解 PEFT。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
