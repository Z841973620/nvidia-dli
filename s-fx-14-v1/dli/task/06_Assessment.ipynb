{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73275a49",
   "metadata": {},
   "source": [
    "<center><img src=\"images/DLI_Header.png\" alt=\"标题\" style=\"width: 400px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e60ab08",
   "metadata": {},
   "source": [
    "# 6. 评估"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890fdc5d",
   "metadata": {},
   "source": [
    "恭喜您完成了所有课程！希望这是一次有趣的旅程，并收获了一些新技能。现在是时候测试这些技能了。\n",
    "\n",
    "在这次评估中，挑战是训练一个能够基于 [MNIST 数据集](https://en.wikipedia.org/wiki/MNIST_database) 生成手写图像的新模型。传统上，神经网络有一个测试数据集，但生成式 AI 不一定如此。情人眼里出西施，而过度拟合是否可以接受则取决于您作为开发人员。\n",
    "\n",
    "因此，我们创建了一个在 MNIST 数据集上训练过的分类器模型。它在 MNIST 测试数据集上的准确率超过 99%。如果这个模型可以正确识别 95% 的生成图像，您将通过评估！"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1083571",
   "metadata": {},
   "source": [
    "## 6.1 数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cb74e7",
   "metadata": {},
   "source": [
    "让我们开始吧，以下是本次评估中使用的库。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c241ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Visualization tools\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision.utils import save_image, make_grid\n",
    "\n",
    "# User defined libraries\n",
    "from utils import other_utils\n",
    "from utils import ddpm_utils\n",
    "from utils import UNet_utils\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d69e9d3",
   "metadata": {},
   "source": [
    "我们之前使用的 FashionMnist 数据集在结构上与 MNIST 类似，因此我们将使用大部分相同的代码来加载它。我们不会随机水平翻转，因为数字通常不应该反向读取。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cf3584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_MNIST(data_transform, train=True):\n",
    "    return torchvision.datasets.MNIST(\n",
    "        \"./data/\",\n",
    "        download=True,\n",
    "        train=train,\n",
    "        transform=data_transform,\n",
    "    )\n",
    "\n",
    "def load_transformed_MNIST(img_size, batch_size):\n",
    "    data_transforms = [\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),  # Scales data into [0,1]\n",
    "    ]\n",
    "\n",
    "    data_transform = transforms.Compose(data_transforms)\n",
    "    train_set = load_MNIST(data_transform, train=True)\n",
    "    test_set = load_MNIST(data_transform, train=False)\n",
    "    data = torch.utils.data.ConcatDataset([train_set, test_set])\n",
    "    dataloader = DataLoader(data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    return data, dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8313fe37",
   "metadata": {},
   "source": [
    "我们将要挑战的分类器模型要求图像大小为 `28 x 28` 像素。图像也是黑白的。一共有 `10` 个类别，每个数字一个。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1e26ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 28\n",
    "IMG_CH = 1\n",
    "BATCH_SIZE = 128\n",
    "N_CLASSES = 10\n",
    "data, dataloader = load_transformed_MNIST(IMG_SIZE, BATCH_SIZE)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613d3353",
   "metadata": {},
   "source": [
    "## 6.2 设置扩散"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b541da32",
   "metadata": {},
   "source": [
    "让我们从设置扩散过程开始。为了节省时间，我们已经在下面列出了 `Beta` 计划的推荐超参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7c61f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 10\n",
    "ncols = 15\n",
    "\n",
    "T = nrows * ncols\n",
    "B_start = 0.0001\n",
    "B_end = 0.02\n",
    "B = torch.linspace(B_start, B_end, T).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e4ad7f",
   "metadata": {},
   "source": [
    "**TODO**：我们仍然需要计算出我们将在 `q` 和 `reverse_q` 函数中使用的一些变量。您可以替换下面的 `FIXME` 吗？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4b81c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1.0 - B\n",
    "a_bar = FIXME(a, dim=0)\n",
    "sqrt_a_bar = FIXME(a_bar)  # Mean Coefficient\n",
    "sqrt_one_minus_a_bar = FIXME(1 - a_bar)  # St. Dev. Coefficient\n",
    "\n",
    "# Reverse diffusion variables\n",
    "sqrt_a_inv = FIXME(1 / a)\n",
    "pred_noise_coeff = (1 - a) / FIXME(1 - a_bar)  # Predicted Noise Coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4247201",
   "metadata": {},
   "source": [
    "**TODO**：下面的 `q` 函数几乎完成了，但我们需要找到图像与噪声的正确比例。怎么做到的？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09a3dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q(x_0, t):\n",
    "        t = t.int()\n",
    "        noise = torch.randn_like(x_0)\n",
    "        sqrt_a_bar_t = sqrt_a_bar[t, None, None, None]\n",
    "        sqrt_one_minus_a_bar_t = sqrt_one_minus_a_bar[t, None, None, None]\n",
    "\n",
    "        x_t = FIXME * x_0 + FIXME * noise\n",
    "        return x_t, noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83430633",
   "metadata": {},
   "source": [
    "请花一点时间来验证结果是否符合您的预期。图像是否一开始清晰可辨，然后就淹没在噪音中了？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a4a6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "x_0 = data[0][0].to(device)\n",
    "xs = []\n",
    "\n",
    "for t in range(T):\n",
    "    t_tenser = torch.Tensor([t]).type(torch.int64)\n",
    "    x_t, _ = q(x_0, t_tenser)\n",
    "    img = torch.squeeze(x_t).cpu()\n",
    "    xs.append(img)\n",
    "    ax = plt.subplot(nrows, ncols, t + 1)\n",
    "    ax.axis('off')\n",
    "    other_utils.show_tensor_image(x_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac62782",
   "metadata": {},
   "source": [
    "**TODO**：`reverse_q` 函数基本完成，但有几个 `FIXME` 。每个 `FIXME` 可以是以下之一：\n",
    "* `x_t` - 潜在图像\n",
    "* `t` - 当前时间步长\n",
    "* `e_t` - 在当前时间步长添加的预测噪声"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4db7204",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def reverse_q(x_t, t, e_t):\n",
    "    t = t.int()\n",
    "    pred_noise_coeff_t = pred_noise_coeff[t]\n",
    "    sqrt_a_inv_t = sqrt_a_inv[t]\n",
    "    u_t = sqrt_a_inv_t * (FIXME - pred_noise_coeff_t * FIXME)\n",
    "    if FIXME[0] == 0:  # All t values should be the same\n",
    "        return u_t  # Reverse diffusion complete!\n",
    "    else:\n",
    "        B_t = B[t - 1]  # Apply noise from the previos timestep\n",
    "        new_noise = torch.randn_like(x_t)\n",
    "        return u_t + torch.sqrt(B_t) * new_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7bf714",
   "metadata": {},
   "source": [
    "## 6.3 设置 U-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674845f5",
   "metadata": {},
   "source": [
    "我们将使用与以前相同的 U-Net 架构："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6427d43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(\n",
    "        self, T, img_ch, img_size, down_chs=(64, 64, 128), t_embed_dim=8, c_embed_dim=10\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.T = T\n",
    "        up_chs = down_chs[::-1]  # Reverse of the down channels\n",
    "        latent_image_size = img_size // 4  # 2 ** (len(down_chs) - 1)\n",
    "        small_group_size = 8\n",
    "        big_group_size = 32\n",
    "\n",
    "        # Inital convolution\n",
    "        self.down0 = ResidualConvBlock(img_ch, down_chs[0], small_group_size)\n",
    "\n",
    "        # Downsample\n",
    "        self.down1 = DownBlock(down_chs[0], down_chs[1], big_group_size)\n",
    "        self.down2 = DownBlock(down_chs[1], down_chs[2], big_group_size)\n",
    "        self.to_vec = nn.Sequential(nn.Flatten(), nn.GELU())\n",
    "\n",
    "        # Embeddings\n",
    "        self.dense_emb = nn.Sequential(\n",
    "            nn.Linear(down_chs[2] * latent_image_size**2, down_chs[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(down_chs[1], down_chs[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(down_chs[1], down_chs[2] * latent_image_size**2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.sinusoidaltime = SinusoidalPositionEmbedBlock(t_embed_dim)\n",
    "        self.t_emb1 = EmbedBlock(t_embed_dim, up_chs[0])\n",
    "        self.t_emb2 = EmbedBlock(t_embed_dim, up_chs[1])\n",
    "        self.c_embed1 = EmbedBlock(c_embed_dim, up_chs[0])\n",
    "        self.c_embed2 = EmbedBlock(c_embed_dim, up_chs[1])\n",
    "\n",
    "        # Upsample\n",
    "        self.up0 = nn.Sequential(\n",
    "            nn.Unflatten(1, (up_chs[0], latent_image_size, latent_image_size)),\n",
    "            GELUConvBlock(up_chs[0], up_chs[0], big_group_size),\n",
    "        )\n",
    "        self.up1 = UpBlock(up_chs[0], up_chs[1], big_group_size)\n",
    "        self.up2 = UpBlock(up_chs[1], up_chs[2], big_group_size)\n",
    "\n",
    "        # Match output channels and one last concatenation\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Conv2d(2 * up_chs[-1], up_chs[-1], 3, 1, 1),\n",
    "            nn.GroupNorm(small_group_size, up_chs[-1]),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(up_chs[-1], img_ch, 3, 1, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, t, c, c_mask):\n",
    "        down0 = self.down0(x)\n",
    "        down1 = self.down1(down0)\n",
    "        down2 = self.down2(down1)\n",
    "        latent_vec = self.to_vec(down2)\n",
    "\n",
    "        latent_vec = self.dense_emb(latent_vec)\n",
    "        t = t.float() / self.T  # Convert from [0, T] to [0, 1]\n",
    "        t = self.sinusoidaltime(t)\n",
    "        t_emb1 = self.t_emb1(t)\n",
    "        t_emb2 = self.t_emb2(t)\n",
    "\n",
    "        c = c * c_mask\n",
    "        c_emb1 = self.c_embed1(c)\n",
    "        c_emb2 = self.c_embed2(c)\n",
    "\n",
    "        up0 = self.up0(latent_vec)\n",
    "        up1 = self.up1(c_emb1 * up0 + t_emb1, down2)\n",
    "        up2 = self.up2(c_emb2 * up1 + t_emb2, down1)\n",
    "        return self.out(torch.cat((up2, down0), 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81457189",
   "metadata": {},
   "source": [
    "**TODO**：遗憾的是，模块的名称已被打乱。您可以根据函数正在执行的操作添加正确的模块名称吗？以下各有一个：\n",
    "* `GELUConvBlock`\n",
    "* `RearrangePoolBlock`\n",
    "* `DownBlock`\n",
    "* `UpBlock`\n",
    "* `SinusoidalPositionEmbedBlock`\n",
    "* `EmbedBlock`\n",
    "* `ResidualConvBlock`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c626b168",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FIXME(nn.Module):\n",
    "    def __init__(self, in_chs, out_chs, group_size):\n",
    "        super(DownBlock, self).__init__()\n",
    "        layers = [\n",
    "            GELUConvBlock(in_chs, out_chs, group_size),\n",
    "            GELUConvBlock(out_chs, out_chs, group_size),\n",
    "            RearrangePoolBlock(out_chs, group_size),\n",
    "        ]\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d1160f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FIXME(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim):\n",
    "        super(EmbedBlock, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        layers = [\n",
    "            nn.Linear(input_dim, emb_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(emb_dim, emb_dim),\n",
    "            nn.Unflatten(1, (emb_dim, 1, 1)),\n",
    "        ]\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.input_dim)\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb3513c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FIXME(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, group_size):\n",
    "        super().__init__()\n",
    "        layers = [\n",
    "            nn.Conv2d(in_ch, out_ch, 3, 1, 1),\n",
    "            nn.GroupNorm(group_size, out_ch),\n",
    "            nn.GELU(),\n",
    "        ]\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e7cb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FIXME(nn.Module):\n",
    "    def __init__(self, in_chs, group_size):\n",
    "        super().__init__()\n",
    "        self.rearrange = Rearrange(\"b c (h p1) (w p2) -> b (c p1 p2) h w\", p1=2, p2=2)\n",
    "        self.conv = GELUConvBlock(4 * in_chs, in_chs, group_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.rearrange(x)\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e16954",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FIXME(nn.Module):\n",
    "    def __init__(self, in_chs, out_chs, group_size):\n",
    "        super().__init__()\n",
    "        self.conv1 = GELUConvBlock(in_chs, out_chs, group_size)\n",
    "        self.conv2 = GELUConvBlock(out_chs, out_chs, group_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.conv2(x1)\n",
    "        out = x1 + x2\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60c7471",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FIXME(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, time):\n",
    "        device = time.device\n",
    "        half_dim = self.dim // 2\n",
    "        embeddings = math.log(10000) / (half_dim - 1)\n",
    "        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n",
    "        embeddings = time[:, None] * embeddings[None, :]\n",
    "        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fdcabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FIXME(nn.Module):\n",
    "    def __init__(self, in_chs, out_chs, group_size):\n",
    "        super(UpBlock, self).__init__()\n",
    "        layers = [\n",
    "            nn.ConvTranspose2d(2 * in_chs, out_chs, 2, 2),\n",
    "            GELUConvBlock(out_chs, out_chs, group_size),\n",
    "            GELUConvBlock(out_chs, out_chs, group_size),\n",
    "            GELUConvBlock(out_chs, out_chs, group_size),\n",
    "            GELUConvBlock(out_chs, out_chs, group_size),\n",
    "        ]\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, skip):\n",
    "        x = torch.cat((x, skip), 1)\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c053d8d",
   "metadata": {},
   "source": [
    "现在已经定义了所有部分，让我们定义模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f68053a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet_utils.UNet(\n",
    "    T, IMG_CH, IMG_SIZE, down_chs=(64, 64, 128), t_embed_dim=8, c_embed_dim=N_CLASSES\n",
    ")\n",
    "print(\"Num params: \", sum(p.numel() for p in model.parameters()))\n",
    "model = torch.compile(model.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566d2d0f",
   "metadata": {},
   "source": [
    "## 6.4 模型训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258ee902",
   "metadata": {},
   "source": [
    "**TODO**：我们应该创建一个函数来随机删除上下文。这个函数是什么？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d570f0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context_mask(c, drop_prob):\n",
    "    c_hot = F.one_hot(c.to(torch.int64), num_classes=N_CLASSES).to(device)\n",
    "    c_mask = torch.FIXME(torch.ones_like(c_hot).float() - drop_prob).to(device)\n",
    "    return c_hot, c_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f820f1d",
   "metadata": {},
   "source": [
    "**TODO**：接下来，让我们定义损失函数。我们应该使用哪种类型的损失函数？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581b37ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(model, x_0, t, *model_args):\n",
    "    x_noisy, noise = q(x_0, t)\n",
    "    noise_pred = model(x_noisy, t/T, *model_args)\n",
    "    return F.FIXME(noise, noise_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cb1a5b",
   "metadata": {},
   "source": [
    "让我们验证模型是否训练正确。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c345ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_images(model, img_ch, img_size, ncols, *model_args, axis_on=False):\n",
    "    # Noise to generate images from\n",
    "    x_t = torch.randn((1, img_ch, img_size, img_size), device=device)\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    hidden_rows = T / ncols\n",
    "    plot_number = 1\n",
    "\n",
    "    # Go from T to 0 removing and adding noise until t = 0\n",
    "    for i in range(0, T)[::-1]:\n",
    "        t = torch.full((1,), i, device=device).float()\n",
    "        e_t = model(x_t, t, *model_args)  # Predicted noise\n",
    "        x_t = reverse_q(x_t, t, e_t)\n",
    "        if i % hidden_rows == 0:\n",
    "            ax = plt.subplot(1, ncols+1, plot_number)\n",
    "            if not axis_on:\n",
    "                ax.axis('off')\n",
    "            other_utils.show_tensor_image(x_t.detach().cpu())\n",
    "            plot_number += 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465e5610",
   "metadata": {},
   "source": [
    "**TODO**：是时候训练模型了！你能修复 `FIXME` 并让它运行起来吗？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650b5070",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "epochs = 5\n",
    "preview_c = 0\n",
    "\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    for step, batch in enumerate(dataloader):\n",
    "        c_drop_prob = FIXME\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        t = torch.randint(0, T, (BATCH_SIZE,), device=device).float()\n",
    "        x = batch[0].to(device)\n",
    "        c_hot, c_mask = get_context_mask(FIXME, c_drop_prob)  # New\n",
    "        loss = get_loss(model, x, t, c_hot, c_mask)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % 1 == 0 and step % 100 == 0:\n",
    "            print(f\"Epoch {epoch} | Step {step:03d} | Loss: {loss.item()} | C: {preview_c}\")\n",
    "            c_drop_prob = 0 # Do not drop context for preview\n",
    "            c_hot, c_mask = get_context_mask(torch.Tensor([preview_c]), c_drop_prob)\n",
    "            sample_images(model, IMG_CH, IMG_SIZE, ncols, c_hot, c_mask)\n",
    "            preview_c = (preview_c + 1) % N_CLASSES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784eb180",
   "metadata": {},
   "source": [
    "## 6.5 采样"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8bedd0",
   "metadata": {},
   "source": [
    "这是拼图的最后一块。我们可以将生成器与分类器进行比较，但就目前情况而言，获得超过 95% 的准确率是非常幸运的。让我们使用 `无分类器扩散引导` 来提高我们的机会。\n",
    "\n",
    "**TODO**：下面的 `sample_w` 函数中有一个 `FIXME` 。您还记得为扩散过程添加权重的函数吗？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b10158",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def sample_w(model, c, w):\n",
    "    input_size = (IMG_CH, IMG_SIZE, IMG_SIZE)\n",
    "    n_samples = len(c)\n",
    "    w = torch.tensor([w]).float()\n",
    "    w = w[:, None, None, None].to(device)  # Make w broadcastable\n",
    "    x_t = torch.randn(n_samples, *input_size).to(device)\n",
    "\n",
    "    # One c for each w\n",
    "    c = c.repeat(len(w), 1)\n",
    "\n",
    "    # Double the batch\n",
    "    c = c.repeat(2, 1)\n",
    "\n",
    "    # Don't drop context at test time\n",
    "    c_mask = torch.ones_like(c).to(device)\n",
    "    c_mask[n_samples:] = 0.0\n",
    "\n",
    "    x_t_store = []\n",
    "    for i in range(0, T)[::-1]:\n",
    "        # Duplicate t for each sample\n",
    "        t = torch.tensor([i]).to(device)\n",
    "        t = t.repeat(n_samples, 1, 1, 1)\n",
    "\n",
    "        # Double the batch\n",
    "        x_t = x_t.repeat(2, 1, 1, 1)\n",
    "        t = t.repeat(2, 1, 1, 1)\n",
    "\n",
    "        # Find weighted noise\n",
    "        e_t = model(x_t, t, c, c_mask)\n",
    "        e_t_keep_c = e_t[:n_samples]\n",
    "        e_t_drop_c = e_t[n_samples:]\n",
    "        e_t = FIXME\n",
    "\n",
    "        # Deduplicate batch for reverse diffusion\n",
    "        x_t = x_t[:n_samples]\n",
    "        t = t[:n_samples]\n",
    "        x_t = reverse_q(x_t, t, e_t)\n",
    "\n",
    "    return x_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e003d964",
   "metadata": {},
   "source": [
    "**TODO**：让我们测试一下。尝试运行下面的单元格几次。你能否通过更改 `w` 使数字始终可识别？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3203fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "w = 0.0  # Change me\n",
    "c = torch.arange(N_CLASSES).to(device)\n",
    "c_drop_prob = 0 \n",
    "c_hot, c_mask = get_context_mask(c, c_drop_prob)\n",
    "\n",
    "x_0 = sample_w(model, c_hot, 1.0)\n",
    "other_utils.to_image(make_grid(x_0.cpu(), nrow=N_CLASSES))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2342b8",
   "metadata": {},
   "source": [
    "这对于自动评分器来说很重要。输出形状是 `[10, 1, 28, 28]` 吗？如果是，您就可以测试模型了！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ed679f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5f7807",
   "metadata": {},
   "source": [
    "## 6.6 运行评估"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b2c329",
   "metadata": {},
   "source": [
    "要评估您的模型，请运行以下两个单元格。\n",
    "\n",
    "**注意**：`run_assessment` 假设您的模型名为 `model` ，扩散权重名为 `w` 。如果您出于任何原因修改了这些变量名称，请更新传递给 `run_assessment` 的参数名称。如果您的结果接近但不完全一样，请尝试更改上面的 `w` 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d3633e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_assessment import run_assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25834296",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_assessment(model, sample_w, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58c0679",
   "metadata": {},
   "source": [
    "<center><img src=\"images/DLI_Header.png\" alt=\"标题\" style=\"width: 400px;\"/></center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
