{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ac135fc",
   "metadata": {},
   "source": [
    "<img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc304c1c",
   "metadata": {},
   "source": [
    "# 构建包含多个深度神经网络 (DNN) 的 DeepStream 应用 #\n",
    "您可构建 DeepStream 工作流水线来执行涉及多个神经网络的复杂分析。其中一个常见用例是：将检测器用作定位物体的主要推理引擎，并将分类器用作辅助推理引擎。此做法十分实用，因为分类模型通常更适用于检测帧内的单个物体。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc4b846",
   "metadata": {},
   "source": [
    "## 学习目标 ##\n",
    "在此 Notebook 中，您将学习如何使用 Python 构建涉及多个神经网络的 DeepStream 工作流水线，并实现以下目标：\n",
    "* 规划工作流水线的架构\n",
    "* 使用规范文件配置深度学习推理\n",
    "* 处理元数据\n",
    "\n",
    "**目录**\n",
    "<br>\n",
    "本 Notebook 涵盖以下部分：\n",
    "1. [设计工作流水线](#s1)\n",
    "    * [练习 #1 - 预览输入视频](#e1)\n",
    "2. [深度学习模型准备工作](#s2)\n",
    "    * [解压 TrafficCamNet 和 VehicleTypeNet 模型](#s2.1)\n",
    "3. [构建视频 AI 应用](#s3)\n",
    "    * [创建和连接工作流水线元件](#s3.1)\n",
    "    * [练习 #2 - 初始化 GStreamer](#e2)\n",
    "    * [练习 #3 - 创建元件](#e3)\n",
    "    * [练习 #4 - 修改 GIE 配置文件](#e4)\n",
    "    * [练习 #5 - 连接元件](#e5)\n",
    "    * [练习 #6 - 向 OSD 汇点添加探针](#e6)\n",
    "    * [练习 #7 - 启动工作流水线](#e7)\n",
    "    * [查看推理](#s3.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f53f38",
   "metadata": {},
   "source": [
    "<a name='s1'></a>\n",
    "## 设计工作流水线 ##\n",
    "构建视频 AI 应用，首先需要根据用例设计项目。在这项活动中，我们将构建 DeepStream 工作流水线，以根据停车场摄像头输入画面准确检测汽车，并对车辆类型进行分类。我们将使用提供的预训练模型。先看一下原始输入视频，然后使用基于 `ffmpeg` 命令行的实用程序来了解其格式。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a06a8a4",
   "metadata": {},
   "source": [
    "<a name='e1'></a>\n",
    "### 练习 #1 - 预览输入视频 ###\n",
    "修改以下单元以研究输入视频。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56154469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "import os\n",
    "\n",
    "# Set the input video path to an environment variable\n",
    "os.environ['TARGET_VIDEO_PATH']='data/sample_30.h264'\n",
    "os.environ['TARGET_VIDEO_PATH_MP4']='sample_30.mp4'\n",
    "\n",
    "target_video_path=os.environ['TARGET_VIDEO_PATH']\n",
    "target_video_path_mp4=os.environ['TARGET_VIDEO_PATH_MP4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f7c58d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "from IPython.display import Video\n",
    "\n",
    "# Convert the H.264 encoded video file to MP4 container file - this will generate the sample_30.mp4 file\n",
    "!ffmpeg -i $TARGET_VIDEO_PATH $TARGET_VIDEO_PATH_MP4 \\\n",
    "        -y \\\n",
    "        -loglevel quiet\n",
    "\n",
    "# View the input video\n",
    "Video(target_video_path_mp4, width=720)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d00da2b-9120-47d0-936a-f2d3595c685e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ffprobe -i <<<<FIXME>>>>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bce0f6-c32c-451a-97bb-d49d2e5fb3d2",
   "metadata": {},
   "source": [
    "请注意下方输出中视频帧的**维度**和**帧速率**。"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d101eb00-6262-4408-8a88-3c30989978f7",
   "metadata": {},
   "source": [
    "Video Codec: <<<<FIXME>>>>\n",
    "Video Color Format: <<<<FIXME>>>>\n",
    "Width: <<<<FIXME>>>>\n",
    "Height: <<<<FIXME>>>>\n",
    "Frame Rate: <<<<FIXME>>>>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "01698b45-7a72-42bb-a78c-d24120a06858",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "!ffprobe -i $TARGET_VIDEO_PATH\n",
    "\n",
    "# Video Codec: h264\n",
    "# Video Color Format: yuv\n",
    "# Width: 882\n",
    "# Height: 692\n",
    "# Frame Rate: 30 fps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2684926c-df0f-45d7-ada3-4d2b9bdd2519",
   "metadata": {},
   "source": [
    "点击 ... 以显示**答案**。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05673df1",
   "metadata": {},
   "source": [
    "<a name='s2'></a>\n",
    "## 深度学习模型准备工作 ##\n",
    "我们将使用 NGC 中的两个专用模型 - [TrafficCamNet](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/tao/models/trafficcamnet) 物体检测模型和 [VehicleTypeNet](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/tao/models/vehicletypenet) 分类模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df659137-7294-4cf0-841a-850ba50b5126",
   "metadata": {},
   "source": [
    "<a name='s2.1'></a>\n",
    "### 解压 TrafficCamNet 和 VehicleTypeNet 模型 ###\n",
    "运行以下单元以解压文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5bd643",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xvf ngc_assets/trafficcamnet_vpruned_v1.0.tar -C ngc_assets/\n",
    "!tar -xvf ngc_assets/vehicletypenet_vpruned_v1.0.tar -C ngc_assets/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f210bf6a",
   "metadata": {},
   "source": [
    "<a name='s3'></a>\n",
    "## 构建视频 AI 应用 ##\n",
    "这是应用的工作流架构。我们将使用物体检测网络来识别和定位各帧中的汽车，然后进行辅助推理，对车辆类型进行分类。\n",
    "<p><img src=\"images/deepstream_multi_gie_pipeline.png\" width='1080'></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcd7c3f",
   "metadata": {},
   "source": [
    "<a name='s3.1'></a>\n",
    "### 创建和连接工作流水线元件 ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e0894d",
   "metadata": {},
   "source": [
    "<a name='e2'></a>\n",
    "### 练习 #2 - 初始化 GStreamer ###\n",
    "修改以下单元以初始化 GStreamer 并实例化工作流水线。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166ffdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# Import necessary GStreamer libraries and DeepStream python bindings\n",
    "import gi\n",
    "gi.require_version('Gst', '1.0')\n",
    "from gi.repository import GObject, Gst, GLib\n",
    "from common.bus_call import bus_call\n",
    "import pyds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f092b858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize GStreamer\n",
    "Gst.<<<<FIXME>>>>\n",
    "\n",
    "# Create Pipeline\n",
    "pipeline=<<<<FIXME>>>>\n",
    "print('Created pipeline')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "09291a8a-0fb5-4425-8646-e84811c6af07",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "# Initialize GStreamer\n",
    "Gst.init(None)\n",
    "\n",
    "# Create Pipeline\n",
    "pipeline=Gst.Pipeline()\n",
    "print('Created pipeline')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b622c6e6",
   "metadata": {},
   "source": [
    "点击 ... 以显示**答案**。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170d2347-196c-4679-ba8b-c750d2a5fe02",
   "metadata": {},
   "source": [
    "<a name='e3'></a>\n",
    "### 练习 #3 - 创建元件 ###\n",
    "修改以下单元以创建必要的工作流元件并设置其属性。您还需根据需要修改配置文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb384c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Source element for reading from a file and set the location property\n",
    "source = Gst.ElementFactory.make(\"filesrc\", \"file-source\")\n",
    "source.set_property('location', \"data/sample_30.h264\")\n",
    "\n",
    "# Create H264 Parser with h264parse as the input file is an elementary h264 stream\n",
    "h264parser = Gst.ElementFactory.make(\"h264parse\", \"h264-parser\")\n",
    "\n",
    "# Create Decoder with nvv4l2decoder for accelerating decoding on GPU\n",
    "decoder = Gst.ElementFactory.make(\"nvv4l2decoder\", \"nvv4l2-decoder\")\n",
    "\n",
    "# Create Streamux with nvstreammux to form batches for one or more sources and set properties\n",
    "streammux = Gst.ElementFactory.make(\"nvstreammux\", \"Stream-muxer\")\n",
    "streammux.set_property('width', 888) \n",
    "streammux.set_property('height', 696) \n",
    "streammux.set_property('batch-size', 1)\n",
    "\n",
    "# Create Primary GStreamer Inference Element with nvinfer to run inference on the decoder's output after batching\n",
    "pgie=Gst.ElementFactory.make(\"nvinfer\", \"primary-inference\")\n",
    "\n",
    "# Create Secondary Inference Element with nvinfer to run inference on the pgie's output\n",
    "sgie=<<<<FIXME>>>>\n",
    "\n",
    "# Create Convertor to convert from YUV to RGBA as required by nvdsosd\n",
    "nvvidconv1=Gst.ElementFactory.make(\"nvvideoconvert\", \"convertor1\")\n",
    "\n",
    "# Create OSD with nvdsosd to draw on the converted RGBA buffer\n",
    "nvosd=Gst.ElementFactory.make(\"nvdsosd\", \"onscreendisplay\")\n",
    "\n",
    "# Create Convertor to convert from RGBA to I420 as required by encoder\n",
    "nvvidconv2=Gst.ElementFactory.make(\"nvvideoconvert\", \"convertor2\")\n",
    "\n",
    "# Create Capsfilter to enforce frame image format\n",
    "capsfilter=Gst.ElementFactory.make(\"capsfilter\", \"capsfilter\")\n",
    "caps=Gst.Caps.from_string(\"video/x-raw, format=I420\")\n",
    "capsfilter.set_property(\"caps\", caps)\n",
    "\n",
    "# Create Encoder to encode I420 formatted frames using the MPEG4 codec\n",
    "encoder=Gst.ElementFactory.make(\"avenc_mpeg4\", \"encoder\")\n",
    "encoder.set_property(\"bitrate\", 2000000)\n",
    "\n",
    "# Create Sink with fakesink as the end point of the pipeline\n",
    "sink=Gst.ElementFactory.make('filesink', 'filesink')\n",
    "sink.set_property('location', 'output_04_raw.mpeg4')\n",
    "sink.set_property(\"sync\", 1)\n",
    "print('Created elements')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5f88fbe9-2f9c-4a3a-9ef1-698de5c6ed93",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "# Create Source element for reading from a file and set the location property\n",
    "source=Gst.ElementFactory.make(\"filesrc\", \"file-source\")\n",
    "source.set_property('location', \"data/sample_30.h264\")\n",
    "\n",
    "# Create H264 Parser with h264parse as the input file is an elementary h264 stream\n",
    "h264parser=Gst.ElementFactory.make(\"h264parse\", \"h264-parser\")\n",
    "\n",
    "# Create Decoder with nvv4l2decoder for accelerating decoding on GPU\n",
    "decoder=Gst.ElementFactory.make(\"nvv4l2decoder\", \"nvv4l2-decoder\")\n",
    "\n",
    "# Create Streamux with nvstreammux to form batches for one or more sources and set properties\n",
    "streammux=Gst.ElementFactory.make(\"nvstreammux\", \"Stream-muxer\")\n",
    "streammux.set_property('width', 888) \n",
    "streammux.set_property('height', 696) \n",
    "streammux.set_property('batch-size', 1)\n",
    "\n",
    "# Create Primary GStreamer Inference Element with nvinfer to run inference on the decoder's output after batching\n",
    "pgie=Gst.ElementFactory.make(\"nvinfer\", \"primary-inference\")\n",
    "\n",
    "# Create Secondary Inference Element with nvinfer to run inference on the pgie's output\n",
    "sgie=Gst.ElementFactory.make(\"nvinfer\", \"secondary-inference\")\n",
    "\n",
    "# Create Convertor to convert from YUV to RGBA as required by nvdsosd\n",
    "nvvidconv1=Gst.ElementFactory.make(\"nvvideoconvert\", \"convertor1\")\n",
    "\n",
    "# Create OSD with nvdsosd to draw on the converted RGBA buffer\n",
    "nvosd=Gst.ElementFactory.make(\"nvdsosd\", \"onscreendisplay\")\n",
    "\n",
    "# Create Convertor to convert from RGBA to I420 as required by encoder\n",
    "nvvidconv2=Gst.ElementFactory.make(\"nvvideoconvert\", \"convertor2\")\n",
    "\n",
    "# Create Capsfilter to enforce frame image format\n",
    "capsfilter=Gst.ElementFactory.make(\"capsfilter\", \"capsfilter\")\n",
    "caps=Gst.Caps.from_string(\"video/x-raw, format=I420\")\n",
    "capsfilter.set_property(\"caps\", caps)\n",
    "\n",
    "# Create Encoder to encode I420 formatted frames using the MPEG4 codec\n",
    "encoder=Gst.ElementFactory.make(\"avenc_mpeg4\", \"encoder\")\n",
    "encoder.set_property(\"bitrate\", 2000000)\n",
    "\n",
    "# Create Sink with fakesink as the end point of the pipeline\n",
    "sink=Gst.ElementFactory.make('filesink', 'filesink')\n",
    "sink.set_property('location', 'output_04_raw.mpeg4')\n",
    "sink.set_property(\"sync\", 1)\n",
    "print('Created elements')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5db10d",
   "metadata": {},
   "source": [
    "点击 ... 以显示**答案**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc79f26-dd9e-4d97-84ab-8b918c933ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# Add elements to pipeline\n",
    "pipeline.add(source)\n",
    "pipeline.add(h264parser)\n",
    "pipeline.add(decoder)\n",
    "pipeline.add(streammux)\n",
    "pipeline.add(pgie)\n",
    "pipeline.add(sgie)\n",
    "pipeline.add(nvvidconv1)\n",
    "pipeline.add(nvosd)\n",
    "pipeline.add(nvvidconv2)\n",
    "pipeline.add(capsfilter)\n",
    "pipeline.add(encoder)\n",
    "pipeline.add(sink)\n",
    "print('Added elements to pipeline')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcf0e17-7774-4f4d-93d5-5cb0bc7eb173",
   "metadata": {},
   "source": [
    "<a name='e4'></a>\n",
    "### 练习 #4 - 修改 GIE 配置文件 ###\n",
    "我们已为您提供[主要 GIE 配置文件](./spec_files/pgie_config_trafficcamnet_04.txt)。请将已启动的辅助 GIE 配置文件修改为 [spec_files/sgie_config_vehicletypenet_04.txt](./spec_files/sgie_config_vehicletypenet_04.txt)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a3107743-1aa0-4245-902f-6f0c60cf0768",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "!cat spec_files/sgie_config_vehicletypenet_04_soln.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13c2627",
   "metadata": {},
   "source": [
    "点击 ... 以显示**答案**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faddf4a-8a70-4404-9dfc-4362c01e4c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# Set the location of the config file\n",
    "pgie.set_property('config-file-path', 'spec_files/pgie_config_trafficcamnet_03.txt')\n",
    "# sgie.set_property('config-file-path', 'spec_files/sgie_config_vehicletypenet_04.txt')\n",
    "sgie.set_property('config-file-path', 'spec_files/sgie_config_vehicletypenet_04.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77727cc8-2889-43aa-ac1f-8e461bd3c1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ngc_assets/vehicletypenet_vpruned_v1.0/labels.txt\n",
    "\n",
    "coupe;largevehicle;sedan;suv;truck;van"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52834278-88f0-4b50-ad3e-cab1a8ff4267",
   "metadata": {},
   "source": [
    "<p><img src='images/tip.png' width=720></p>\n",
    "\n",
    "对于分类器，应以分号分隔 `labels.txt`。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f654ec82",
   "metadata": {},
   "source": [
    "<a name='e5'></a>\n",
    "### 练习 #5 - 连接元件 ###\n",
    "修改以下单元以连接元件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9598d3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Link elements together\n",
    "source.link(h264parser)\n",
    "h264parser.link(decoder)\n",
    "\n",
    "# Link decoder source pad to streammux sink pad\n",
    "decoder_srcpad=decoder.get_static_pad(\"src\")    \n",
    "streammux_sinkpad=streammux.get_request_pad(\"sink_0\")\n",
    "decoder_srcpad.link(streammux_sinkpad)\n",
    "\n",
    "# Link the rest of the elements in the pipeline\n",
    "streammux.link(pgie)\n",
    "pgie.<<<<FIXME>>>>\n",
    "<<<<FIXME>>>>.link(nvvidconv1)\n",
    "nvvidconv1.link(nvosd)\n",
    "nvosd.link(nvvidconv2)\n",
    "nvvidconv2.link(capsfilter)\n",
    "capsfilter.link(encoder)\n",
    "encoder.link(sink)\n",
    "print('Linked elements in pipeline')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a5997f37-2a60-4caf-976f-7d1fb18e5a70",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "# Link elements together\n",
    "source.link(h264parser)\n",
    "h264parser.link(decoder)\n",
    "\n",
    "# Link decoder source pad to streammux sink pad\n",
    "decoder_srcpad=decoder.get_static_pad(\"src\")    \n",
    "streammux_sinkpad=streammux.get_request_pad(\"sink_0\")\n",
    "decoder_srcpad.link(streammux_sinkpad)\n",
    "\n",
    "# Link the rest of the elements in the pipeline\n",
    "streammux.link(pgie)\n",
    "pgie.link(sgie)\n",
    "sgie.link(nvvidconv1)\n",
    "nvvidconv1.link(nvosd)\n",
    "nvosd.link(nvvidconv2)\n",
    "nvvidconv2.link(capsfilter)\n",
    "capsfilter.link(encoder)\n",
    "encoder.link(sink)\n",
    "print('Linked elements in pipeline')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4397053b",
   "metadata": {},
   "source": [
    "点击 ... 以显示**答案**。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bc406a-a8ca-476b-a479-bf27e5a42f8b",
   "metadata": {},
   "source": [
    "<a name='e6'></a>\n",
    "### 练习 #6 - 向 OSD 接收衬垫添加探针 ###\n",
    "修改以下单元以添加探针。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4398acd",
   "metadata": {
    "tags": []
   },
   "source": [
    "另外，我们还需要遍历辅助推理所生成的元数据。在本示例中，辅助推理是分类器对主要推理中的 `car` 类执行推理。我们可以在使用 `NvDsClassifierMeta.cast()` 投射元数据后访问 `classifier_meta_list` 中生成的元数据。根据辅助推理的次数，`NvDsObjectMeta` 对象可能包含一个或多个 `NvDsClassifierMeta` 对象。我们还需要投射到 `NvDsLabelInfo` 类，以获取辅助推理的结果分类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2ac517-14be-4890-ba17-f593b08b88f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# Define the Probe Function\n",
    "def osd_sink_pad_buffer_probe(pad, info):\n",
    "    gst_buffer = info.get_buffer()\n",
    "\n",
    "    # Retrieve batch metadata from the gst_buffer\n",
    "    # Note that pyds.gst_buffer_get_nvds_batch_meta() expects the\n",
    "    # C address of gst_buffer as input, which is obtained with hash(gst_buffer)\n",
    "    batch_meta = pyds.gst_buffer_get_nvds_batch_meta(hash(gst_buffer))\n",
    "    l_frame = batch_meta.frame_meta_list\n",
    "\n",
    "    # Iterate through each frame in the batch metadata until the end\n",
    "    while l_frame is not None:\n",
    "        try:\n",
    "            frame_meta = pyds.NvDsFrameMeta.cast(l_frame.data)\n",
    "        except StopIteration:\n",
    "            break\n",
    "\n",
    "        frame_num=frame_meta.frame_num\n",
    "        num_obj = frame_meta.num_obj_meta\n",
    "        l_obj=frame_meta.obj_meta_list\n",
    "        \n",
    "        print(\"Frame Number={} Number of Objects={}\".format(frame_num, num_obj))\n",
    "        \n",
    "        # Iterate through each object in the frame metadata until the end\n",
    "        while l_obj is not None:\n",
    "            try:\n",
    "                obj_meta=pyds.NvDsObjectMeta.cast(l_obj.data)\n",
    "                \n",
    "                # Define an analyze_meta function to manipulate metadata\n",
    "                analyze_meta(obj_meta)\n",
    "            except StopIteration:\n",
    "                break\n",
    "                \n",
    "            try: \n",
    "                l_obj=l_obj.next\n",
    "            except StopIteration:\n",
    "                break\n",
    "        \n",
    "        try:\n",
    "            l_frame=l_frame.next\n",
    "        except StopIteration:\n",
    "            break\n",
    "    return Gst.PadProbeReturn.OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d03822-f77b-4511-bcee-4e28b27d8456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "PGIE_CLASS_ID_CAR=0\n",
    "\n",
    "# Define helper function\n",
    "def analyze_meta(obj_meta): \n",
    "    # Only car supports secondary inference\n",
    "    if obj_meta.class_id == PGIE_CLASS_ID_CAR:     \n",
    "        cls_meta=obj_meta.classifier_meta_list\n",
    "        \n",
    "        # Iterate through each class meta until the end\n",
    "        while cls_meta is not None:\n",
    "            cls=pyds.NvDsClassifierMeta.cast(cls_meta.data)\n",
    "            # Get label info\n",
    "            label_info=cls.label_info_list  \n",
    "            \n",
    "            # Iterate through each label info meta until the end\n",
    "            while label_info is not None:\n",
    "                # Cast data type of label from pyds.GList\n",
    "                label_meta=pyds.glist_get_nvds_label_info(label_info.data)\n",
    "                if cls.unique_component_id==2:\n",
    "                    print('\\t Type & Probability = {}% {}'.format(round(label_meta.result_prob*100), label_meta.result_label))\n",
    "                try:\n",
    "                    label_info=label_info.next\n",
    "                except StopIteration:\n",
    "                    break\n",
    "            \n",
    "            try:\n",
    "                cls_meta=cls_meta.next\n",
    "            except StopIteration:\n",
    "                break\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d41b872-3b11-4006-806f-d723ffb44efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add probe to nvdsosd plugin's sink\n",
    "osdsinkpad = nvosd.get_static_pad(\"sink\")\n",
    "osdsinkpad.add_probe(<<<<FIXME>>>>, <<<<FIXME>>>>)\n",
    "print('Attached probe')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1f062789-6c6e-4e3c-b78c-6a24db197415",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "# Add probe to nvdsosd plugin's sink\n",
    "osdsinkpad=nvosd.get_static_pad(\"sink\")\n",
    "osdsinkpad.add_probe(Gst.PadProbeType.BUFFER, osd_sink_pad_buffer_probe)\n",
    "print('Attached probe')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b482704",
   "metadata": {},
   "source": [
    "点击 ... 以显示**答案**。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624a96c6",
   "metadata": {},
   "source": [
    "<a name='e7'></a>\n",
    "### 练习 #7 - 启动工作流水线 ###\n",
    "修改以下单元，以启动 DeepStream 工作流水线。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d5ae3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# Create an event loop\n",
    "loop=GLib.MainLoop()\n",
    "\n",
    "# Feed GStreamer bus messages to loop\n",
    "bus=pipeline.get_bus()\n",
    "bus.add_signal_watch()\n",
    "bus.connect (\"message\", bus_call, loop)\n",
    "print('Added bus message handler')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733862d5-bd5d-4bc2-ae20-fbcc40f306e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting pipeline \\n\")\n",
    "pipeline.set_state(<<<<FIXME>>>>)\n",
    "try: \n",
    "    loop.<<<<FIXME>>>>\n",
    "except: \n",
    "    pass\n",
    "\n",
    "pipeline.set_state(Gst.State.NULL)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ec7c6fa7-0ceb-48b4-9cb3-a8ca9432018d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "# Start play back and listen to events - this will generate the output_04_raw.mpeg4 file\n",
    "print(\"Starting pipeline \\n\")\n",
    "pipeline.set_state(Gst.State.PLAYING)\n",
    "try:\n",
    "    loop.run()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Cleaning up as the pipeline comes to an end\n",
    "pipeline.set_state(Gst.State.NULL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de483317-ba3d-47bb-bd00-dc77392b669b",
   "metadata": {},
   "source": [
    "点击 ... 以显示**答案**。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ff8380",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name='s3.3'></a>\n",
    "### 查看推理 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e81868",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# Convert MPEG4 video file to MP4 container file\n",
    "!ffmpeg -i /dli/task/output_04_raw.mpeg4 /dli/task/output_04.mp4 \\\n",
    "        -y \\\n",
    "        -loglevel quiet\n",
    "\n",
    "# View the output video\n",
    "Video(\"output_04.mp4\", width=720)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec251116",
   "metadata": {},
   "source": [
    "<img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
