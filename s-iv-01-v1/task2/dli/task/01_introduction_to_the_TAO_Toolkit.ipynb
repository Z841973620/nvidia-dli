{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7492effa",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e435d5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# TAO 工具包简介 #\n",
    "训练、适应和优化 (TAO：Train Adapt Optimize) 工具包是用于简化 AI/ML 模型开发工作流程的框架。利用该框架，开发者能够使用自定义数据对预训练模型作出微调，以高效生成非常准确的计算机视觉模型，从而消除对大量训练和深度 AI 专业知识的需求。此外，该框架还支持模型优化以实现推理性能。\n",
    "\n",
    "<p><img src=\"images/tao_toolkit.png\" width=720></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c6e6fc-d435-46db-b0e7-cb9a502f094b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 学习目标 ##\n",
    "在此 Notebook 中，您可通过学习以下内容，了解便于您有效使用 TAO 工具包的必备基础知识：\n",
    "* 视频 AI 模型训练挑战\n",
    "* 什么是迁移学习\n",
    "* 如何优化 AI 模型以构建视频 AI 应用\n",
    "* 如何使用 TAO 工具包 CLI\n",
    "* TAO 工具包支持的预训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cbe3bf-73bf-476c-9bea-db337196ad9f",
   "metadata": {
    "tags": []
   },
   "source": [
    "**目录**<br>\n",
    "本 Notebook 包括以下部分：\n",
    "1. [视频 AI 模型训练工作流程](#s1)\n",
    "    * [深度学习的挑战](#s1.1)\n",
    "    * [迁移学习](#s1.2)\n",
    "    * [用于视频 AI 的 TAO 工具包](#s1.3)\n",
    "2. [受支持的视频 AI 预训练模型](#s2)\n",
    "3. [TAO 工具包工作流程](#s3)\n",
    "    * [TAO 启动程序、CLI（命令行接口）和规格文件](#s3.1)\n",
    "    * [练习 #1 - 探索 TAO 工具包 CLI](#e1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe69bb6d",
   "metadata": {},
   "source": [
    "<a name='s1'></a>\n",
    "## 视频 AI 模型训练的工作流程 ## \n",
    "视频 AI 应用的核心是一个或多个深度学习模型，这些模型可用于提取汽车检测和分类等深入分析数据。此类模型经调优和优化，可提供相适水平的准确性和性能。构建深度学习模型涉及多个步骤，其中包括收集规模较大的高质量数据集、准备数据、训练模型以及优化模型以供部署。在训练神经网络模型时，我们可以借助这些模型的功能，从原始数据中自动提取特征并将这些特征与目标关联起来。如果使用更多的数据进行训练，深度学习模型的性能还将提高，但整个过程不仅十分耗时，而且计算量庞大。完成模型训练后，即可加以部署并将之用于推理。鉴于所涉及计算的复杂性，模型规模可能很大，会限制视频 AI 应用的性能。为确保流分析工作流程的有效性，视频 AI 模型必须在不牺牲准确性的前提下高效运行。\n",
    "<p><img src='images/video_ai_model_training_workflow.png' width=720></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f19d8e-5127-4a1e-b041-634e60a018e7",
   "metadata": {},
   "source": [
    "<a name='s1.1'></a>\n",
    "### 深度学习的挑战 ###\n",
    "为视频 AI 应用构建深度学习模型存在一些常见的挑战：\n",
    "* 需要学习一个或多个深度学习框架，例如 [TensorFlow](https://www.tensorflow.org/)、[PyTorch](https://pytorch.org/) 或 [Caffe](https://caffe.berkeleyvision.org/)。\n",
    "* 从头开始训练准确的深度学习模型需要大量的数据，而采集这些数据的过程成本高昂。\n",
    "* 在针对推理和生产就绪型任务进行优化之前，需要投入大量精力微调深度学习模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790a96b2-973e-45d8-ba58-994fe5374e88",
   "metadata": {},
   "source": [
    "<a name='s1.2'></a>\n",
    "### 迁移学习 ###\n",
    "在实践中，由于数据稀缺（训练样本数量不足）或训练时间过长等因素，在随机初始化权重值的网络上启动学习任务这一做法并不常见，且效率低下。克服这一问题最常见的解决方案之一是使用迁移学习。迁移学习是将学习到的特征从一个应用程序转移到另一个应用程序的过程。这是一项常用的训练技术，开发人员使用在一个任务上训练的模型并重新训练以将其用于不同的任务。这种做法非常高效，因为对于类似任务而言，神经网络中靠前的那些层的用途都相同。例如，卷积神经网络中用于计算机视觉 (CV) 模型前面的多个层主要用于识别图像的轮廓、曲线和其他特征。可将这些层组成的网络视作更复杂模型的**主干**网络。此类网络又称为特征提取器，它以图像作为其输入，并提取特征图，网络的其余部分以这些特征图为基础。从这些层学习到的特征可以应用于在其他领域的执行相同识别的类似任务。迁移学习使现有的神经网络能够适应（微调）到新的神经网络，而所需要的特定领域的数据要少得多，进而大幅降低对特定领域的数据的需求。大多数情况下，微调时间会大大减少（通常会减少 10 倍），从而能够节省时间和资源。就视觉 AI 而言，迁移学习能够通过将权重从一个应用转移到另一个应用来适应场景，从而适应新的视角或相机角度。迁移学习还可用于添加新的分类。\n",
    "\n",
    "<p><img src='images/transfer_learning.png' width=720></p>\n",
    "\n",
    "有关迁移学习的更多信息，请参阅此[博客文章](https://blogs.nvidia.com/blog/2019/02/07/what-is-transfer-learning/)。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f599bd-e5f9-40ca-9249-6304088569bd",
   "metadata": {},
   "source": [
    "<a name='s1.3'></a>\n",
    "### 用于视频 AI 的 TAO 工具包 ###\n",
    "TAO 工具包使用预训练模型来加速 AI 开发过程，能够降低与大规模数据采集、添加标记以及从头开始训练模型相关的成本。使用预训练模型的迁移学习可用于面向智慧城市、零售、医疗健康、工业检测等领域的视频 AI 应用。TAO 工具包具备以下实用功能：\n",
    "* 无需写代码，不需要 AI 框架的专业知识，为任何有意构建视频人工智能应用的人员降低了入门门槛。\n",
    "* 配置灵活，支持自定义，可帮助用户加速推进原型设计。\n",
    "* 提供大量生产就绪型预训练模型，可用于处理常见的计算机视觉任务，也支持使用用户自己的数据定制这些模型。\n",
    "* 易于使用的界面，适用于剪枝和量化感知训练等模型优化任务。\n",
    "* 集成 DeepStream SDK。\n",
    "<p><img src='images/transfer_learning.jpg' width=540></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fc59be",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name='s2'></a>\n",
    "## 所支持的视频 AI 预训练模型 ##\n",
    "构建视频 AI 应用和服务的开发者、系统组装商和软件合作伙伴可以引入自己的自定义数据来快速训练和微调预训练模型，而不再需要采集庞大的数据，以及从头开始训练。用户可以从两类预训练模型入手：**通用视觉模型**和**专门构建的预训练模型**。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891b2303-264e-42f2-aa5c-afd38e32c54f",
   "metadata": {},
   "source": [
    "* **通用视觉模型** 为流行的网络架构提供预训练的权重，以训练图像分类模型、物体检测模型或分割模型。这为用户提供了为任意数量的应用程序构建 AI 模型的灵活性和控制权，包括用于边缘部署的小型轻量级模型，以及可处理更复杂任务的大型模型。这些模型经由[开放图像](https://opensource.google/projects/open-images-dataset)数据集训练而成，与从头训练或从随机权重开始训练相比，它们为训练提供了更好的起点。\n",
    "\n",
    "    TAO 工具包会根据自定义数据调整流行的网络架构和主干，支持开发者训练、微调、剪枝和导出经过高度优化且准确的 AI 模型。在使用 TAO 时，首先选择要构建的模型架构，然后选择一个受支持的主干。\n",
    "<p><img src='images/tao_matrix.png' width=720></p>\n",
    "\n",
    "    _请注意：每个特征提取网络的预训练权重仅是构建的起始点，如果不重新训练就不能使用。此外，预训练权重针对具体网络而定，不应在使用不同架构的模型之间共享。_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572943d6-9ae3-48a2-85b1-715c8c826b24",
   "metadata": {},
   "source": [
    "* **专门构建的预训练模型**是产品级模型，专为实现高准确性和高性能而设计。此类模型经由数百万个对象训练而成，用于执行常见的视频 AI 任务，并为智慧城市、零售、公共安全、医疗健康等应用提供良好的起点。[NGC](https://ngc.nvidia.com/) 上免费提供专门构建的模型。我们为每个模型都准备了一个可以按原样部署的剪枝版本或一个未剪枝版本，可用于针对特定用例使用更多数据进行重新训练。\n",
    "<p><img src='images/purpose-built_models_table.png' width=720></p>\n",
    "\n",
    "    请在[此处](https://docs.nvidia.com/tao/tao-toolkit/text/overview.html#pre-trained-models)查找完整列表和详细信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9d9ebe-4910-47bf-a704-1f55fad0aaa1",
   "metadata": {},
   "source": [
    "* _TAO 工具包不支持任何第三方预训练模型。目前仅支持 NGC 中的 NVIDIA 预训练模型，并且可以使用自定义数据重新训练这些模型。_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee42fc11",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name='s3'></a>\n",
    "### TAO 工具包工作流程 ###\n",
    "构建视频 AI 系统和应用并非易事。针对企业部署需求定制单个组件更是难上加难。针对特定领域的应用部署通常需要经历多个周期的重新训练、微调和模型部署，直到满足要求为止。其中涉及的步骤如下：\n",
    "\n",
    "0. 配置\n",
    "1. 从 NGC 下载预训练模型\n",
    "2. 准备训练数据\n",
    "3. 使用迁移学习训练模型\n",
    "4. 评估目标预测模型\n",
    "5. 优化模型的推理性能\n",
    "6. 导出用于推理的模型\n",
    "\n",
    "<p><img src='images/tao_toolkit_workflow.png' width=1080></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d52b603",
   "metadata": {},
   "source": [
    "<a name='s3.1'></a>\n",
    "### TAO 启动程序、CLI（命令行接口）和规格文件 ###\n",
    "TAO 工具包是零编码框架，可轻松入门。该框架使用**启动程序**从 NGC 注册表中提取并实例化相应的 TAO 容器来执行所需的子任务，例如转换数据、训练、评估或导出模型。用户使用**命令行界面**与启动程序进行交互，该界面经由简单的 [**Protocol Buffer**](https://developers.google.com/protocol-buffers) **规范文件**配置而成，包含数据集参数、模型参数、优化器和训练时的超参数等参数。有关 TAO 工具包启动程序的更多信息，请参阅 [TAO 文档](https://docs.nvidia.com/tao/tao-toolkit/text/tao_launcher.html#tao-launcher)。\n",
    "\n",
    "_请注意：TAO 工具包附带一组具有默认参数值的参考脚本和配置规范，可帮助开发者顺利启动训练和微调。这些资源降低了该套件的入门门槛，用户即使对模型没有深入了解、不具备深度学习专业知识，或者初涉编码技能领域，也能够训练新模型并微调预训练模型。_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba658a8-0124-44fa-b655-e1093ae9df01",
   "metadata": {},
   "source": [
    "**TAO 启动程序 CLI 入门**\n",
    "\n",
    "可以使用命令行的以下约定从 TAO 工具包的启动程序中调用任务：`tao <任务> <子任务> <args_per_subtask>`, 其中 `<args_per_subtask>`是给定子任务所需的参数。容器启动后，子任务将由 TAO 工具包容器使用相应的硬件资源运行。\n",
    "<p><img src='images/tao_launcher.gif' width=720></p>\n",
    "\n",
    "如需了解所支持的不同功能的使用情况，请选择 `--help`。如需了解更多信息，请参阅 [TAO 工具包快速入门指南](https://docs.nvidia.com/tao/tao-toolkit/text/tao_toolkit_quick_start_guide.html)。\n",
    "**输出示例**如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176afd1c-4326-442e-9021-1828dde70f7f",
   "metadata": {},
   "source": [
    "```Python\n",
    "用法：tao [-h]\n",
    "           {list,stop,info,action_recognition,augment,bpnet,classification,converter,detectnet_v2,dssd,efficientdet,emotionnet,faster_rcnn,fpenet,gazenet,gesturenet,heartratenet,intent_slot_classification,lprnet,mask_rcnn,multitask_classification,n_gram,punctuation_and_capitalization,question_answering,retinanet,spectro_gen,speech_to_text,speech_to_text_citrinet,ssd,text_classification,token_classification,unet,vocoder,yolo_v3,yolo_v4,yolo_v4_tiny}\n",
    "           ...\n",
    "\n",
    "TAO 工具包启动程序。\n",
    "\n",
    "可选参数：\n",
    "  -h，--help            显示此帮助信息并退出\n",
    "\n",
    "任务：\n",
    "  {list,stop,info,action_recognition,augment,bpnet,classification,converter,detectnet_v2,dssd,efficientdet,emotionnet,faster_rcnn,fpenet,gazenet,gesturenet,heartratenet,intent_slot_classification,lprnet,mask_rcnn,multitask_classification,n_gram,punctuation_and_capitalization,question_answering,retinanet,spectro_gen,speech_to_text,speech_to_text_citrinet,ssd,text_classification,token_classification,unet,vocoder,yolo_v3,yolo_v4,yolo_v4_tiny}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8939251-1122-4713-9ce3-9bddbaa8cc7c",
   "metadata": {},
   "source": [
    "<p><img src='images/important.png' width=720></p>\n",
    "\n",
    "**在本课程中，我们不会使用 TAO 启动程序。相反，我们的环境已经过设置，可用于模拟已经在运行的 TAO 工具包容器内部的工作。**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6e6aea",
   "metadata": {},
   "source": [
    "利用 TAO 工具包，用户可以训练物体检测、分类、分割、光学字符识别、面部特征点预测、视线估计等模型。在 TAO 的术语中，我们将这些训练称为**任务**，而任务又分为 `train`、`prune`、`evluate`、`export` 等**子任务**。每个任务/子任务都需要通过不同的配置文件组合来适应不同的参数，例如数据集参数、模型参数、以及优化器和训练超参数。TAO 工具包易于使用的部分原因在于，大部分参数都已按照实验规范文件（规格文件）的形式隐藏了起来。相关参数详情可参考[入门指南](https://docs.nvidia.com/tao/archive/tlt-10/pdf/Transfer-Learning-Toolkit-Getting-Started-Guide-IVA.pdf)。在使用 TAO 工具包时，您可随时访问这些资源以为自己提供帮助。此外，我们还提供了一些特定任务，可协助处理已启动的命令。可选任务如下所列。由于对话式 AI 的任务不在本课程范围之内，因此我们已将此类任务变灰。\n",
    "\n",
    "<img src='images/tao_tasks.png' width=740>\n",
    "\n",
    "我们可以使用 `--help` 选项来探索不同任务的功能。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a411426-1856-44e2-bb0e-3393d527baf6",
   "metadata": {},
   "source": [
    "<a name='e1'></a>\n",
    "#### 练习 #1：探索 TAO 工具包 CLI ####\n",
    "一起来探索一些 TAO 工具包任务。\n",
    "\n",
    "**说明**：<br>\n",
    "* 仅需修改 `<FIXME>` 并执行单元即可，在`[classification、detectnet_v2、mask_rcnn、emotionnet 等]`中选择任务，接着在`[calibration_tensorfile、dataset_convert、evaluate、export、inference、prune、train]`中选择子任务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf32d9c-0338-4c60-805b-6177451d33a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: !detectnet_v2 train --help\n",
    "!<FIXME> <FIXME> --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80833b81",
   "metadata": {},
   "source": [
    "**您做得很好**！准备就绪后，我们开始学习[下一个 Notebook](./02_preparation_for_model_training.ipynb)。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028db191",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
