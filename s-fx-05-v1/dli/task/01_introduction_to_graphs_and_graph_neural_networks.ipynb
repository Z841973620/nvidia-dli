{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6042d4e-9a79-4779-adff-1a809e1532d6",
   "metadata": {
    "id": "f6042d4e-9a79-4779-adff-1a809e1532d6"
   },
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b175ac1",
   "metadata": {
    "id": "4b175ac1"
   },
   "source": [
    "# 图神经网络入门"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fe182d-930e-424b-bcff-5bb95fa216ed",
   "metadata": {
    "id": "e2fe182d-930e-424b-bcff-5bb95fa216ed"
   },
   "source": [
    "## 01 - 图和图神经网络简介 ##\n",
    "在本 Notebook 中，您将学习图和图神经网络的基本概念。\n",
    "\n",
    "**目录**\n",
    "<br>\n",
    "本 Notebook 包括以下部分：\n",
    "1. [图简介](#s1-1)\n",
    "    * [处理图数据](#s1-1.1)\n",
    "    * [练习 #1 - 构建一个简单的图](#s1-e1)\n",
    "    * [处理节点特征和边特征](#s1-1.2)\n",
    "    * [图数据的表示](#s1-1.3)\n",
    "2. [数据集概述](#s1-2)\n",
    "    * [探索性地分析数据](#s1-2.1)\n",
    "    * [练习 #2 - 查找连接数最多的节点](#s1-e2)\n",
    "    * [数据准备和子图](#s1-2.2)\n",
    "3. [构建用于节点分类的图神经网络](#s1-3)\n",
    "    * [消息传递和图卷积](#s1-3.1)\n",
    "4. [使用 PyTorch 构建 GNN](#s1-4)\n",
    "    * [求和池化](#s1-4.1)\n",
    "    * [基准 MLP 模型](#s1-4.2)\n",
    "    * [练习 #3 - 平均池化](#s1-e3)\n",
    "    * [图卷积网络 (GCN)](#s1-4.3)\n",
    "5. [使用 DGL 的内置模组构建 GNN](#s1-5)\n",
    "    * [GraphConv](#s1-5.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d50743-60f7-4d97-8490-7f0137c2b8b4",
   "metadata": {
    "id": "32d50743-60f7-4d97-8490-7f0137c2b8b4"
   },
   "source": [
    "<a name='s1-1'></a>\n",
    "## 图简介 ##\n",
    "图是一种包含**节点**和**边**的数据结构。节点可以是人员、地点或事物；边用于定义节点之间的关系。边可以是有向的，其中每个边都有一个源节点和一个目标节点。边也可以是无向的，没有源节点或目标节点。图在处理复杂的关系和交互问题方面表现出色。\n",
    "\n",
    "能够自然地以图表示的数据包括：\n",
    "* **引文网络**可用于研究出版物之间的关系。\n",
    "* **社交网络**这一工具可用于研究人员、机构和组织的集体行为模式。社交网络图可表示人员群组，方法是将人员建模为节点，并将他们的社交关系建模为边。\n",
    "* **分子**可描述为图，其中节点是原子，边是共价键。\n",
    "\n",
    "图的结构可能会因节点的数量、边的数量和节点连接情况不同而大相径庭。\n",
    "\n",
    "使图有别于其他类型数据的部分属性包括：\n",
    "1. 图存在于非欧几里德空间中，这增加了解读数据的难度。为直观呈现数据，市面上提供了各种降维工具以供选择。\n",
    "2. 图是非结构化的，并没有固定的形式。\n",
    "3. 图的大尺寸和高维度特征增加了人类解读此类数据的复杂性。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5511f98a-2059-4422-964c-fef8ca92399d",
   "metadata": {
    "id": "5511f98a-2059-4422-964c-fef8ca92399d",
    "tags": []
   },
   "source": [
    "<a name='s1-1.1'></a>\n",
    "### 处理图数据 ###\n",
    "在本实验中，我们将使用开源 Deep Graph Library [(DGL)](https://www.dgl.ai/) 和 [PyTorch](https://pytorch.org/) 处理图数据。其他热门的图深度学习库包括 [Spektral](https://graphneural.network/)、[Graph Nets](https://www.deepmind.com/open-source/graph-nets) 和 [PyTorch Geometric](https://www.pyg.org/)，这些库让我们能够以类似方式处理图数据。\n",
    "\n",
    "DGL 使用具有唯一性的整数（也称为节点 ID）来表示每个节点，并使用与端点节点的 ID 对应的整数对来表示每条边。DGL 会根据边添加至图的顺序，给每条边分配具有唯一性的整数（从 `0` 开始，也称为边 ID）。在 DGL 中，所有边都是有向的，边 `(u, v)` 表示它是从源节点 `u` 指向目标节点 `v` 的边。创建**无向**图时，可以通过添加**反向边**，将边视为**双向**边。\n",
    "\n",
    "首先，我们创建下方的示例图：\n",
    "\n",
    "<p><img src='images/sample_graph_1.png' width=240></p>\n",
    "\n",
    "您可以使用 [`dgl.graph(data)`](https://docs.dgl.ai/en/0.9.x/generated/dgl.graph.html) 创建 [`DGLGraph`](https://docs.dgl.ai/en/latest/api/python/dgl.DGLGraph.html)，并使用一对节点 ID `(U, V)` 来表示源节点和目标节点。完成创建后，我们可以使用 [`dgl.DGLGraph.nodes()`](https://docs.dgl.ai/en/0.8.x/generated/dgl.DGLGraph.nodes.html)、[`dgl.DGLGraph.edges()`](https://docs.dgl.ai/en/0.8.x/generated/dgl.DGLGraph.edges.html) 或 [`dgl.DGLGraph.edge_ids(u, v)`](https://docs.dgl.ai/generated/dgl.DGLGraph.edge_ids.html) 引用节点和边。我们还可以使用 [`dgl.DGLGraph.find_edges(eid)`](https://docs.dgl.ai/en/0.8.x/generated/dgl.DGLGraph.find_edges.html)、[`dgl.DGLGraph.in_edges(v)`](https://docs.dgl.ai/en/0.8.x/generated/dgl.DGLGraph.in_edges.html) 或 [`dgl.DGLGraph.out_edges(u)`](https://docs.dgl.ai/en/0.8.x/generated/dgl.DGLGraph.out_edges.html) 识别边。要确定节点度（即连接数），我们可以使用 [`dgl.DGLGraph.in_degrees(v)`](https://docs.dgl.ai/en/0.8.x/generated/dgl.DGLGraph.in_degrees.html) 或 [`dgl.DGLGraph.out_degrees(u)`](https://docs.dgl.ai/en/0.8.x/generated/dgl.DGLGraph.out_degrees.html)。我们可以选择使用 [`networkx`](https://networkx.org/) 直观呈现小图。\n",
    "\n",
    "_注意：如需进一步了解 DGLGraph API（包括[查询基本图结构](https://docs.dgl.ai/en/0.7.x/api/python/dgl.DGLGraph.html#querying-graph-structure)属性），请单击 [此处](https://docs.dgl.ai/en/0.7.x/api/python/dgl.DGLGraph.html)。_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87526336-e6fa-40b1-823d-ed970b8595f3",
   "metadata": {
    "id": "87526336-e6fa-40b1-823d-ed970b8595f3"
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# import dependencies\n",
    "import dgl\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ea4a03-6e3d-493c-80c5-1c0c24b2bc9f",
   "metadata": {
    "id": "a2ea4a03-6e3d-493c-80c5-1c0c24b2bc9f"
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# create source nodes for edges (2, 1), (3, 2), (4, 3)\n",
    "sample_u=[2, 3, 4]\n",
    "\n",
    "# create destination nodes for edges (2, 1), (3, 2), (4, 3)\n",
    "sample_v=[1, 2, 3]\n",
    "\n",
    "# create graph\n",
    "sample_g=dgl.graph((sample_u, sample_v))\n",
    "\n",
    "# print graph\n",
    "print(sample_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06597dbc-7995-403e-830d-d078bb07beb2",
   "metadata": {
    "id": "06597dbc-7995-403e-830d-d078bb07beb2"
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# print node IDs\n",
    "print(\"Node IDs are: \\n{}\\n\".format(sample_g.nodes()))\n",
    "\n",
    "# print the source and destination nodes of every edge\n",
    "print(\"Source & destination nodes of every edge are: \\n{}\\n\".format(sample_g.edges()))\n",
    "\n",
    "# print edge IDs\n",
    "print(\"Edge IDs are: \\n{}\".format(sample_g.edge_ids(sample_u, sample_v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce198789-f5fe-4364-8273-49cd28ca140c",
   "metadata": {
    "id": "ce198789-f5fe-4364-8273-49cd28ca140c"
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# make bidirected graph\n",
    "sample_g=dgl.to_bidirected(sample_g)\n",
    "\n",
    "# dgl.add_reverse_edges(graph) achieves similar result\n",
    "# sample_g=dgl.add_reverse_edges(sample_g)\n",
    "\n",
    "# print graph properties\n",
    "print(\"Node IDs are: \\n{}\\n\".format(sample_g.nodes()))\n",
    "print(\"Source & destination nodes of every edge are: \\n{}\\n\".format(sample_g.edges()))\n",
    "print(\"Edge IDs for directed graph are: \\n{}\\n\".format(sample_g.edge_ids(sample_u, sample_v)))\n",
    "\n",
    "# print all edges\n",
    "print(\"Edge IDs for bidirectional/undirected graph are: \\n{}\".format(sample_g.edge_ids(sample_u+sample_v, sample_v+sample_u)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3965913c-db77-465a-9b76-b585aec97e64",
   "metadata": {
    "id": "3965913c-db77-465a-9b76-b585aec97e64"
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# find all edges connected to node 1\n",
    "node_id=1\n",
    "print(\"Source node(s) {0[0]} are connected to destination node(s) {0[1]}. \".format(sample_g.in_edges(node_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d124723-c874-46f8-94c2-4a7109a004db",
   "metadata": {
    "id": "7d124723-c874-46f8-94c2-4a7109a004db"
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# get node degrees\n",
    "print(\"Node degrees for all nodes: \\n{}\".format(sample_g.in_degrees()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb1e26d-af21-4ab8-b79c-59a0c9762fd6",
   "metadata": {
    "id": "ebb1e26d-af21-4ab8-b79c-59a0c9762fd6"
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# visualize the graph\n",
    "import networkx as nx\n",
    "\n",
    "# draw plot using networkx\n",
    "G=dgl.to_networkx(sample_g)\n",
    "nx.draw_networkx(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2701ba36-9067-456f-bf79-ad5b1332d13b",
   "metadata": {
    "id": "2701ba36-9067-456f-bf79-ad5b1332d13b"
   },
   "source": [
    "_注意：此图由 5 个节点和 3 条边组成。节点数量是根据给定边中的最大节点 ID 自动推断出来的。此外，边 ID 将根据边的添加顺序自动编号，对于双向/无向图，边将进行两次编号。_ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8df054e-2575-4cbd-ac71-915e2b595833",
   "metadata": {
    "id": "e8df054e-2575-4cbd-ac71-915e2b595833"
   },
   "source": [
    "<a name='s1-e1'></a>\n",
    "### 练习 #1 - 构建一个简单的图 ###\n",
    "我们来创建下方的图。\n",
    "\n",
    "<p><img src='images/sample_graph_2.png' width=240></p>\n",
    "\n",
    "**说明**：<br>\n",
    "* 仅修改 `<FIXME>` 以创建示例图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b610d629-32c7-4e82-bd90-4af90f71ed5a",
   "metadata": {
    "id": "b610d629-32c7-4e82-bd90-4af90f71ed5a"
   },
   "outputs": [],
   "source": [
    "# create sources nodes and destination nodes\n",
    "u=<<<<FIXME>>>>\n",
    "v=<<<<FIXME>>>>\n",
    "g=dgl.graph((u, v))\n",
    "\n",
    "# when making undirected graphs, edges are treated as bidirectional\n",
    "g=dgl.to_bidirected(g)\n",
    "\n",
    "# draw plot using networkx\n",
    "nx.draw_networkx(dgl.to_networkx(g))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a7c83bfd-4756-4609-8b05-7406ecc2606d",
   "metadata": {
    "id": "a7c83bfd-4756-4609-8b05-7406ecc2606d",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "u=[0, 1, 2, 3, 3, 4]\n",
    "v=[1, 2, 3, 4, 5, 5]\n",
    "g=dgl.graph((u, v))\n",
    "g=dgl.to_bidirected(g)\n",
    "\n",
    "nx.draw_networkx(dgl.to_networkx(g))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e62a2a2-0bca-4427-a864-ee7c8d3bd6f7",
   "metadata": {
    "id": "7e62a2a2-0bca-4427-a864-ee7c8d3bd6f7"
   },
   "source": [
    "单击 ... 即可显示**解决方案**。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134cf1cd-ad51-498f-8487-c7b22c71dfb6",
   "metadata": {
    "id": "134cf1cd-ad51-498f-8487-c7b22c71dfb6"
   },
   "source": [
    "<a name='s1-1.2'></a>\n",
    "### 处理节点特征和边特征 ###\n",
    "许多图数据都包含节点和边特征。我们可以通过 [`dgl.DGLGraph.ndata`](https://docs.dgl.ai/en/latest/generated/dgl.DGLGraph.ndata.html#dgl.DGLGraph.ndata) 和 [`dgl.DGLGraph.edata`](https://docs.dgl.ai/en/latest/generated/dgl.DGLGraph.edata.html#dgl.DGLGraph.edata) 接口分配和检索节点和边特征，类似于在 [Python 字典](https://docs.python.org/3/tutorial/datastructures.html#dictionaries) 中添加/检索键值对的方式。`ndata` 和 `edata` 还可以用于存储 `labels` 和 `train`/`test masks`等深度学习的其他节点级和边级数据。此外，还有关于整个图的全局属性。\n",
    "\n",
    "_注意：DGLGraph 仅接受存储为数值[张量](https://pytorch.org/docs/stable/tensors.html)的特征。随着深度学习的广泛发展，我们可以通过多种方式将各类属性编码为数值特征。_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b2bbc7-5cc8-4fe7-9e4b-325815f6b1d5",
   "metadata": {
    "id": "d7b2bbc7-5cc8-4fe7-9e4b-325815f6b1d5"
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# print ndata\n",
    "print(\"Node data: \\n{}\\n\".format(g.ndata))\n",
    "\n",
    "# print edata\n",
    "print(\"Edge data: \\n{}\".format(g.edata))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcad1af-9e70-41db-8df7-c54f5e7beb7e",
   "metadata": {
    "id": "ebcad1af-9e70-41db-8df7-c54f5e7beb7e"
   },
   "source": [
    "下面，我们演示如何将随机值分配为节点特征向量。我们使用 [`dgl.DGLGraph.num_nodes()`](https://docs.dgl.ai/generated/dgl.DGLGraph.num_nodes.html#dgl.DGLGraph.num_nodes) 函数来获取图中的节点数量，然后使用 `dgl.DGLGraph.ndata` 分配一个名为 `feat` 的随机多维节点特征向量。我们也可以使用 [`dgl.DGLGraph.num_edges()`](https://docs.dgl.ai/en/0.8.x/generated/dgl.DGLGraph.num_edges.html?highlight=num%20edges#dgl.DGLGraph.num_edges) 和 `dgl.DGLGraph.edata` 进行类似的分配。\n",
    "\n",
    "_注意：节点和边特征可以随意命名，就像我们为 Python 字典的密钥任意命名一样。例如，我们可以将节点特征命名为 `f_n`，而非 `feat`。_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3b7dcf-568d-41e8-87cd-4524838bb7d6",
   "metadata": {
    "id": "3c3b7dcf-568d-41e8-87cd-4524838bb7d6"
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# get number of nodes\n",
    "num_nodes=g.num_nodes()\n",
    "\n",
    "# assign a 4-dimensional random node feature vector called feat for each node\n",
    "g.ndata['feat']=torch.randn(num_nodes, 4)\n",
    "\n",
    "# print node features\n",
    "print(\"Node features ({}): \\n{}\\n\".format(g.ndata['feat'].shape, g.ndata))\n",
    "\n",
    "# assign a 5-dimensional random edge feature vector called f_e for each edge\n",
    "num_edges=g.num_edges()\n",
    "g.edata['f_e']=torch.randn(num_edges, 5)\n",
    "print(\"Edge features ({}): \\n{}\".format(g.edata['f_e'].shape, g.edata))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fc7297-1f14-424e-9cc6-28979c5f7993",
   "metadata": {
    "id": "05fc7297-1f14-424e-9cc6-28979c5f7993"
   },
   "source": [
    "<a name='s1-1.3'></a>\n",
    "### 图数据的表示 ###\n",
    "图通常以**邻接矩阵**表示。如果一个图有 `n` 个节点，那么邻接矩阵的维度就是 `n` x `n`。矩阵包含 `取值 0 或 1 的` 向量，以指示源节点和目标节点之间是否存在连接。虽然 [`dgl.DGLGraph.adj()`](https://docs.dgl.ai/en/0.8.x/generated/dgl.DGLGraph.adj.html?highlight=adj) 返回的是[稀疏张量](https://pytorch.org/docs/stable/sparse.html)，但我们可以进一步将其转换为稠密张量，使其在视觉上更加直观。在我们的示例图中，邻接矩阵如下所示：\n",
    "\n",
    "<p><img src='images/adj_matrix.png' width=240></p>\n",
    "\n",
    "不过，尽管将图结构可视化为邻接矩阵，可能非常方便且直观，但如果它是稀疏张量（充满零），这通常不是最高效的做法。**邻接表**是我们表示边的另一种方式。它们将节点之间的边连接性描述为一维张量 `(v, u)` 的元组，以表示所有边的目标节点和源节点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3087a848-f7cc-4c8b-938e-b288500df4ea",
   "metadata": {
    "id": "3087a848-f7cc-4c8b-938e-b288500df4ea"
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# print adjacency matrix as a sparse Tensor\n",
    "print(\"Adjacency matrix (sparse Tensor): \\n{}\\n\".format(g.adj()))\n",
    "\n",
    "# print adjacency matrix as a dense Tensor\n",
    "print(\"Adjacency matrix (dense Tensor): \\n{}\".format(g.adj().to_dense()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0208de1f-06cb-4609-a729-11aed9a292a0",
   "metadata": {
    "id": "0208de1f-06cb-4609-a729-11aed9a292a0"
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# manually calculate node degrees and use .long() to convert to integers\n",
    "g.ndata['degree']=g.adj().to_dense().sum(axis=1).long()\n",
    "\n",
    "# print node degrees\n",
    "print(\"Node degrees computed manually: \\n{}\\n\".format(g.ndata['degree']))\n",
    "\n",
    "# node degrees can also be obtained via DGL API\n",
    "print(\"Node degrees via DGL API: \\n{}\".format(g.in_degrees()))\n",
    "\n",
    "# features can also be deleted, analogous to Dictionary entries\n",
    "del g.ndata['degree']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2407ba44-0a21-468d-b5e3-db1975d99d4e",
   "metadata": {
    "id": "2407ba44-0a21-468d-b5e3-db1975d99d4e"
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# print destination and source nodes for all edges as adjacency lists\n",
    "u=g.edges()[0].tolist()\n",
    "v=g.edges()[1].tolist()\n",
    "print(\"Edges: \\n{}\".format(list(zip(u, v))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b66bb4b-ae9e-4d09-8b7c-52b1996e918c",
   "metadata": {
    "id": "0b66bb4b-ae9e-4d09-8b7c-52b1996e918c"
   },
   "source": [
    "<a name='s1-2'></a>\n",
    "## 数据集概述 ##\n",
    "为确保演示贴合实际，我们将使用来自 [**O**pen **G**raph **B**enchmark](https://ogb.stanford.edu/) 的 [`ogbn-arxiv`](https://ogb.stanford.edu/docs/nodeprop/#ogbn-arxiv) 数据集。`ogbn-arxiv` 数据集是一个有向图，表示计算机科学(CS) arXiv 文献之间的引文网络。每个节点是一篇 arXiv 文献，每个有向边表示一篇文献引用了另一篇文献。每篇文献都有一个 128 维 [word2vec](https://en.wikipedia.org/wiki/Word2vec) 特征向量。这个示例很好地说明了如何使用 GNN 利用图中嵌入的信息进行预测。\n",
    "\n",
    "每个节点都能归入 arXiv CS 文献的 40 个主题之一，例如 cs.AI、cs.LG 和 cs.OS，具体由文献的作者和 arXiv 审核人手动确定和标记。\n",
    "\n",
    "虽然某些数据集可能包含多个图，但 `ogbn-arxiv` 数据集只包含一个图，且起始位置为 `0`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b005379-1352-42b6-95fc-997bb5be9749",
   "metadata": {
    "id": "2b005379-1352-42b6-95fc-997bb5be9749"
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# import dependencies\n",
    "from ogb.nodeproppred import DglNodePropPredDataset\n",
    "\n",
    "# load data\n",
    "dataset=DglNodePropPredDataset(name='ogbn-arxiv')\n",
    "\n",
    "# assign graph and labels\n",
    "g, labels=dataset[0]\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf621dd-94f1-4352-b003-f79fe2169fed",
   "metadata": {
    "id": "0cf621dd-94f1-4352-b003-f79fe2169fed"
   },
   "source": [
    "<a name='s1-2.1'></a>\n",
    "### 探索性地分析数据 ###\n",
    "\n",
    "为进一步了解数据集，我们将执行一些基本的探索性数据分析。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc25cec3-3846-4294-9633-53f164327b19",
   "metadata": {
    "id": "fc25cec3-3846-4294-9633-53f164327b19"
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# print node keys\n",
    "print(\"Node dict keys: \\n{}\\n\".format(g.ndata.keys()))\n",
    "\n",
    "# print node feature shape\n",
    "print(\"Node feature shape (num_of_nodes x num_of_features): \\n{}\\n\".format(g.ndata['feat'].shape))\n",
    "\n",
    "# print number of nodes\n",
    "print(\"Number of nodes: \\n{}\\n\".format(g.num_nodes()))\n",
    "      \n",
    "# print number of edges\n",
    "print(\"Number of edges: \\n{}\".format(g.num_edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf7f572-1a01-4ed4-a81f-c23fd4033b1a",
   "metadata": {
    "id": "bcf7f572-1a01-4ed4-a81f-c23fd4033b1a"
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# print labels\n",
    "print(\"Labels shape: \\n{}\\n\".format(labels.shape))\n",
    "print(\"Label classes: \\n{}\".format(labels.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdb597a-7769-4c81-94f6-b33bb8d5e600",
   "metadata": {
    "id": "8bdb597a-7769-4c81-94f6-b33bb8d5e600"
   },
   "source": [
    "<a name='s1-e2'></a>\n",
    "### 练习 #2 - 查找连接数最多的节点 ###\n",
    "我们来查找连接数（即度）最高的节点。\n",
    "\n",
    "**说明**：<br>\n",
    "* 仅修改 `<FIXME>` 以查找连接数最多的节点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c990b60-6b6b-4bec-870c-986685abeaa7",
   "metadata": {
    "id": "6c990b60-6b6b-4bec-870c-986685abeaa7"
   },
   "outputs": [],
   "source": [
    "# placeholder for max node id and max connections count\n",
    "max_node_id=0\n",
    "max_count=0\n",
    "\n",
    "# iterate through all nodes\n",
    "for each_node in g.nodes(): \n",
    "    # check if number of connections is larger than current max\n",
    "    count=len(g.<<<<FIXME>>>>(each_node)[0])\n",
    "    if count>max_count: \n",
    "        \n",
    "        # set max_count and max_node_id\n",
    "        max_count=count\n",
    "        max_node_id=each_node\n",
    "\n",
    "# print node with most connections\n",
    "print(\"Node_{} has the most connections. \".format(max_node_id))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f70ada07-8a6f-4626-9359-ab5c43833cbe",
   "metadata": {
    "id": "f70ada07-8a6f-4626-9359-ab5c43833cbe",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "max_node_id=0\n",
    "max_count=0\n",
    "\n",
    "for each_node in g.nodes(): \n",
    "    count=len(g.in_edges(each_node)[0])\n",
    "    if count>max_count: \n",
    "        max_count=count\n",
    "        max_node_id=each_node\n",
    "\n",
    "print(\"Node_{} has the most connections. \".format(max_node_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f18989-2eb1-4685-b7b9-872c9b5c9bd6",
   "metadata": {
    "id": "69f18989-2eb1-4685-b7b9-872c9b5c9bd6"
   },
   "source": [
    "单击 ... 即可显示**解决方案**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f84bd8-b4f9-4b3c-ad4c-8a3c214f4e71",
   "metadata": {
    "id": "91f84bd8-b4f9-4b3c-ad4c-8a3c214f4e71"
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# Node degrees can also be accessed via `.in_degrees()` or `.out_degrees()`\n",
    "print(\"Node degrees via DGL API: \\n{}\\n\".format(g.in_degrees()))\n",
    "\n",
    "# print node with most connections\n",
    "print(\"Node_{} has the most connections. \".format(torch.argmax(g.in_degrees())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9c844e-40ba-439b-a15b-96ac7b51324a",
   "metadata": {
    "id": "cd9c844e-40ba-439b-a15b-96ac7b51324a"
   },
   "source": [
    "<a name='s1-2.2'></a>\n",
    "### 数据准备和子图 ###\n",
    "在使用数据集进行机器学习之前，我们将执行数据拆分以验证模型。原始数据集包含 169,343 个节点和 1,116,243 条边。数据拆分的依据是文献发表日期。通过在发表时间较早的文献上训练模型，我们随后可以使用该模型预测新发表的文献的标签。这可为 arXiv 审核人带来巨大的价值。鉴于数据所包含的历史范围，我们将 2017 年及之前发表的文献作为训练集，2018 年发表的文献作为验证集，2019 年及之后发表的文献作为测试集。OGB 数据加载器可为我们直接、便利地提供`train`（训练集）、`valid`（验证集） 和 `test`（测试集）的筛选掩码。\n",
    "\n",
    "我们首先使用一个数据子集进行演示。具体而言，由于我们要使用密集邻接矩阵来构建第一个 GNN，我们的内存容量仅够装下节点的子集。DGL 提供了一个便捷的 [`dgl.DGLGraph.subgraph(nodes)`](https://docs.dgl.ai/en/0.2.x/generated/dgl.DGLGraph.subgraph.html) 函数来帮助我们实现这一目标。通过查看新图中的节点特征 `dgl.NID` 或边特征 `dgl.EID`，我们可以获得从子图映射到原图的节点/边。此外，`subgraph` 会将初始特征复制到子图中。在了解 GNN 的工作原理后，我们将能使用稀疏邻接矩阵训练整个数据集。\n",
    "\n",
    "_注意：尽管 `ogbn-arxiv` 数据集表示有向图，但我们会忽略边方向并将其视为无向。_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e032a34d-2ac2-4d5e-aa4d-80c49831fa07",
   "metadata": {
    "id": "e032a34d-2ac2-4d5e-aa4d-80c49831fa07"
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# import dependencies\n",
    "import numpy as np\n",
    "\n",
    "# assign number of labels\n",
    "num_classes=6\n",
    "\n",
    "# get subset of node indices\n",
    "sub_nodes=np.where(np.isin(labels, range(num_classes)))[0]\n",
    "\n",
    "# get subset of labels\n",
    "sub_labels=labels[np.isin(labels, range(num_classes))]\n",
    "\n",
    "# get subgraph and make bidirectional/undirected\n",
    "sub_g=g.subgraph(sub_nodes)\n",
    "sub_g=dgl.to_bidirected(sub_g, copy_ndata=True)\n",
    "print(sub_g)\n",
    "\n",
    "# print parent node IDs\n",
    "parent_nodes=sub_g.ndata[dgl.NID]\n",
    "print(\"Parent node IDs: {}\".format(parent_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea2c9d6-a829-479f-a1d1-485d46063b10",
   "metadata": {
    "id": "5ea2c9d6-a829-479f-a1d1-485d46063b10"
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# get data split\n",
    "split_idx=dataset.get_idx_split()\n",
    "\n",
    "# get train, valid, and test splits\n",
    "train_idx, valid_idx, test_idx=split_idx[\"train\"], split_idx[\"valid\"], split_idx[\"test\"]\n",
    "\n",
    "# DO NOT CHANGE THIS CELL\n",
    "# sample subset for the train, valid, and test set using parent_nodes\n",
    "train_mask=[True if idx in train_idx else False for idx in parent_nodes]\n",
    "valid_mask=[True if idx in valid_idx else False for idx in parent_nodes]\n",
    "test_mask=[True if idx in test_idx else False for idx in parent_nodes]\n",
    "\n",
    "print(\"{} nodes for training: \\n{} nodes for validation: \\n{} nodes for testing. \".format(sum(train_mask), sum(valid_mask), sum(test_mask)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7878d7-5b6a-4624-ac7c-4404870ae616",
   "metadata": {
    "id": "9c7878d7-5b6a-4624-ac7c-4404870ae616"
   },
   "source": [
    "<a name='s1-3'></a>\n",
    "## 构建用于节点分类的图神经网络 ##\n",
    "图数据颇具挑战性，因为标准的深度学习方法主要关注结构化数据，例如固定大小的像素网格（图像）和序列（文本）。图神经网络 (**GNN**) 是指在图上应用深度学习的各种不同方法：\n",
    "* 充分利用图结构\n",
    "* 根据图大小及其特征来考量可扩展性和效率\n",
    "* 提供轻松完成节点级、边级和图级预测任务的方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700d1849-9aa3-4ef6-80f6-90956125a4f8",
   "metadata": {
    "id": "700d1849-9aa3-4ef6-80f6-90956125a4f8"
   },
   "source": [
    "<a name='s1-3.1'></a>\n",
    "### 消息传递和图卷积 ###\n",
    "**消息传递**是指图中每个节点将自身信息发送给邻域节点，并接收它们回复的消息，以更新其状态并了解其环境。它使图神经网络能够通过关联邻域节点发送的消息（特征）来更新节点的特征，从而探索图的连接性。消息传递功能是 DGL 库的核心，DGL 中的大多数图计算都有赖于此功能。消息传递可视为两个主要步骤：\n",
    "1. 第一步包括\"消息\"阶段，即节点将消息发送或散布到其邻域节点处。执行对象是图中所有的边或者相关的边。\n",
    "2. 第二步是\"化简\"阶段，其中消息由接收节点进行**聚合**，并用于更新其特征。执行对象是图中所有的节点或相关的节点。\n",
    "\n",
    "**图[卷积](https://en.wikipedia.org/wiki/Convolution)**结合了来自邻域的信息，并将更新的节点特征编码为*潜隐表示*。它可基于简单的消息传递机制实现，其中涉及邻域特征的线性组合，且聚合使用的权重仅取决于图结构。\n",
    "\n",
    "* [嵌入](https://en.wikipedia.org/wiki/Embedding)指的是一个相对低维的空间，我们可以将高维向量转换到其中，使相似的项目彼此靠近。\n",
    "\n",
    "我们将通过不同的节点分类图神经网络来演示这些基本机制。简而言之，节点分类是指通过评估邻域节点的特征和信息来预测特定节点的标签的任务。\n",
    "\n",
    "<p><img src='images/gnn_node_classification.png' width=720></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f156a8-3505-48da-9d34-e31e4a0ab486",
   "metadata": {
    "id": "05f156a8-3505-48da-9d34-e31e4a0ab486"
   },
   "source": [
    "<a name='s1-4'></a>\n",
    "## 使用 PyTorch 构建 GNN ##\n",
    "[PyTorch](https://pytorch.org/) 是一个基于 Python 编程语言和 [Torch](http://torch.ch/) 库的开源机器学习框架。它旨在用于创建深度神经网络，非常适合深度学习研究。我们首先使用 PyTorch 来定义图神经网络的层，以演示基本机制。稍后我们将在实验中探索构建图神经网络的其他方法。\n",
    "\n",
    "下面，我们将通过定义一个简单的双层图神经网络，来探索各种方法。第一层将矩阵乘法应用到特征向量、邻接矩阵以及权重矩阵上。我们还会将生成的矩阵传递给深度学习的非线性激活函数。此层将允许我们实施 `sum-pooling` 和 `mean-pooling` 等各种聚合方案。\n",
    "\n",
    "除了 GNN 模型之外，我们还将定义一个评估函数和一个训练函数，以便进行标准的深度学习模型训练。由于我们训练的是分类模型，因此我们将计算[负对数似然损失](https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html) (`nll_loss`) 作为损失，并将准确率（`accuracy`）作为评估指标。\n",
    "\n",
    "<p><img src='images/aggregation.png' width=960></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbbc6aa-cb40-483e-b51f-8277434683aa",
   "metadata": {
    "id": "2dbbc6aa-cb40-483e-b51f-8277434683aa"
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# import dependencies\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5550ade-747a-414f-be75-e91d8b61cb5d",
   "metadata": {
    "id": "b5550ade-747a-414f-be75-e91d8b61cb5d"
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# define SimpleGraphNet\n",
    "class SimpleGraphNet(nn.Module):\n",
    "    \"\"\"Simple graph neural network\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    in_feats (int): input feature size\n",
    "    h_feats (int): hidden feature size\n",
    "    num_classes (int): number of classes\n",
    "    \"\"\"\n",
    "    def __init__(self, in_feats, h_feats, num_classes):\n",
    "        # for inheritance we use super() to refer to the base class\n",
    "        super(SimpleGraphNet, self).__init__()\n",
    "        \n",
    "        # two linear layers where each one will have its own weights, W\n",
    "        # first layer computes the hidden layer\n",
    "        self.layer1 = nn.Linear(in_feats, h_feats)\n",
    "        # use num_classes units for the second layer to compute the classification of each node\n",
    "        self.layer2 = nn.Linear(h_feats, num_classes)\n",
    "\n",
    "    def forward(self, g, h, adj): \n",
    "        \"\"\"Forward computation\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        g (DGLGraph): the input graph\n",
    "        h (Tensor): the input node features\n",
    "        adj (Tensor): the graph adjacency matrix\n",
    "        \"\"\"\n",
    "        # apply first linear layer's transform weights \n",
    "        x=self.layer1(h)\n",
    "        \n",
    "        # perform matrix multiplication with the adjacency matrix and node features to \n",
    "        # aggregate/recombine across neighborhoods\n",
    "        x=torch.mm(adj, x)\n",
    "        \n",
    "        # apply a relu activation function\n",
    "        x=F.relu(x)\n",
    "        \n",
    "        # apply second linear layer's transform weights\n",
    "        x=self.layer2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450a66a2-bbb7-4e7a-9917-1cabd78640e3",
   "metadata": {
    "id": "450a66a2-bbb7-4e7a-9917-1cabd78640e3"
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# import dependencies\n",
    "import time\n",
    "\n",
    "# define evaluate\n",
    "def evaluate(model, g, adj, labels, mask):\n",
    "    \"\"\"Model evaluation for particular set\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model (nn.Module): the model\n",
    "    features (Tensor): the feature tensor\n",
    "    adj (Tensor): the graph adjacency matrix\n",
    "    labels (Tensor): the ground truth labels\n",
    "    mask (Tensor): the mask for a specific subset\n",
    "    \"\"\"\n",
    "    # assign features\n",
    "    features=g.ndata['feat']\n",
    "    \n",
    "    # set to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # put features through model to obtain logits \n",
    "        logits=model(g, features, adj)\n",
    "        \n",
    "        # get logits and labels for particular set\n",
    "        logits=logits[mask]\n",
    "        labels=labels[mask]\n",
    "        \n",
    "        # get most likely class and count the number of corrects\n",
    "        _, indices = torch.max(logits, dim=1)\n",
    "        correct = torch.sum(indices == labels)\n",
    "        \n",
    "        # return accuracy\n",
    "        return correct.item() * 1.0 / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b81874-8b3f-4b47-86cb-7ed784187721",
   "metadata": {
    "id": "c9b81874-8b3f-4b47-86cb-7ed784187721"
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# define train\n",
    "def train(model, g, adj, labels):\n",
    "    \"\"\"Model training\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model (nn.Module): the model\n",
    "    features (Tensor): the feature tensor\n",
    "    adj (Tensor): the graph adjacency matrix\n",
    "    labels (Tensor): the ground truth labels\n",
    "    \"\"\"\n",
    "    # assign features\n",
    "    features=g.ndata['feat']\n",
    "    \n",
    "    # use a standard optimization pipeline using the adam optimizer\n",
    "    optimizer=torch.optim.Adam(model.parameters(), lr=0.02)\n",
    "\n",
    "    # standard training pipeline with early stopping\n",
    "    best_acc=0.0\n",
    "    for epoch in range(200): \n",
    "        start=time.time()\n",
    "\n",
    "        # set to training mode\n",
    "        model.train()\n",
    "        \n",
    "        # forward step\n",
    "        # calculate logits and loss\n",
    "        logits=model(g, features, adj)\n",
    "        # calculate loss using log_softmax and negative log likelihood\n",
    "        logp=F.log_softmax(logits, 1)\n",
    "        loss=F.nll_loss(logp[train_mask], labels[train_mask])\n",
    "\n",
    "        # backward step\n",
    "        # zero out gradients before accumulating the gradients on backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # apply the optimizer to the gradients\n",
    "        optimizer.step()\n",
    "        \n",
    "        # evaluate on validation and test sets\n",
    "        val_acc=evaluate(model, g, adj, labels, valid_mask)\n",
    "        test_acc=evaluate(model, g, adj, labels, test_mask)\n",
    "        \n",
    "        # compare validation accuracy with best accuracy at 10 epoch intervals, which will update if exceeded\n",
    "        if (epoch%10==0) & (val_acc>best_acc):\n",
    "            best_acc=val_acc\n",
    "            print(\"Epoch {:03d} | Loss {:.4f} | Validation Acc {:.4f} | Test Acc {:.4f} | Time(s) {:.4f}\".format(\n",
    "                epoch, loss.item(), val_acc, test_acc, time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc47446a-1cb1-4859-862f-da063cc8324b",
   "metadata": {
    "id": "dc47446a-1cb1-4859-862f-da063cc8324b"
   },
   "source": [
    "<a name='s1-4.1'></a>\n",
    "### 求和池化 ###\n",
    "作为切入点，我们将使用 `sum-pooling` 聚合训练简单的图神经网络，以执行节点分类。回想一下，`sum-pooling` 可能会导致与特征扩展相关的问题，并且可能无法给出最佳结果。\n",
    "\n",
    "<p><img src='images/sum-pooling.PNG' width=240></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f826f40-41a3-4cfa-a80a-852d649bae46",
   "metadata": {
    "id": "0f826f40-41a3-4cfa-a80a-852d649bae46"
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# create adjacency matrix\n",
    "adj=sub_g.adj().to_dense()\n",
    "\n",
    "# modify the adjacency matrix by adding the identity matrix to ensure nodes consider their own features\n",
    "adj=adj+torch.eye(sub_g.adj().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addd668e-8f57-46b0-beb6-74615886192e",
   "metadata": {
    "id": "addd668e-8f57-46b0-beb6-74615886192e",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# instantiate simple model\n",
    "model=SimpleGraphNet(sub_g.ndata['feat'].shape[1], 32, num_classes)\n",
    "\n",
    "# print model architecture\n",
    "print(model)\n",
    "\n",
    "# start training\n",
    "train(model, sub_g, adj, sub_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a42ebd9-1da4-424b-b4c7-6c8fd82c9ec8",
   "metadata": {
    "id": "3a42ebd9-1da4-424b-b4c7-6c8fd82c9ec8"
   },
   "source": [
    "<a name='s1-4.2'></a>\n",
    "### 基准 MLP 模型 ###\n",
    "我们可以使用[单位矩阵](https://en.wikipedia.org/wiki/Identity_matrix)来测试模型，而非邻接矩阵。这相当于创建一个标准的 MLP 分类模型，在不同顶点上共享权重。我们可以将此作为基准，了解图卷积的改进程度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022376c3-c462-4a45-9981-8b6780ba8bca",
   "metadata": {
    "id": "022376c3-c462-4a45-9981-8b6780ba8bca"
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# modify the adjacency matrix by adding the identity matrix to ensure nodes consider their own features\n",
    "adj=torch.eye(sub_g.adj().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e94173f-27a5-4874-9dab-17b3cae59507",
   "metadata": {
    "id": "0e94173f-27a5-4874-9dab-17b3cae59507",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# instantiate simple model\n",
    "model=SimpleGraphNet(sub_g.ndata['feat'].shape[1], 32, num_classes)\n",
    "\n",
    "# print model architecture\n",
    "print(model)\n",
    "\n",
    "# start training\n",
    "train(model, sub_g, adj, sub_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd827d3-1be2-43c5-b6c7-e0b26e1796a1",
   "metadata": {
    "id": "3fd827d3-1be2-43c5-b6c7-e0b26e1796a1"
   },
   "source": [
    "<a name='s1-e3'></a>\n",
    "### 练习  #3 - 平均池化 ###\n",
    "使用 `mean-pooling` 聚合的图神经网络会对向量进行归一化，以防止特征呈爆炸式增长，因为输出特征的规模可能会有所增大。\n",
    "\n",
    "<p><img src='images/mean-pooling.PNG' width=240></p>\n",
    "\n",
    "**说明**：<br>\n",
    "* 仅修改 `<FIXME>` 以计算每个节点的连接数。\n",
    "* 执行以下单元，使用 `mean-pooling` 聚合训练用于节点分类的 GNN。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161d031c-e758-44c0-b4f6-4654e446c85e",
   "metadata": {
    "id": "161d031c-e758-44c0-b4f6-4654e446c85e"
   },
   "outputs": [],
   "source": [
    "# create adjacency matrix\n",
    "adj=sub_g.adj().to_dense()\n",
    "\n",
    "# modify the adjacency matrix by adding the identity matrix to ensure nodes consider their own features\n",
    "adj=adj+torch.eye(sub_g.adj().shape[0])\n",
    "\n",
    "# get node degrees\n",
    "deg=<<<<FIXME>>>>\n",
    "\n",
    "# divide the adjacency matrix by the degree matrix, which is equivalent to multiplying it with the \n",
    "# inverse of the degree matrix. This gives a normalize propagation rule, which should hopefully deal with \n",
    "# any exploding signal that we might have\n",
    "adj=adj/deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d88278-3177-4a76-9456-d358598323cf",
   "metadata": {
    "id": "f0d88278-3177-4a76-9456-d358598323cf",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# instantiate simple model\n",
    "model=SimpleGraphNet(sub_g.ndata['feat'].shape[1], 32, num_classes)\n",
    "\n",
    "# print model architecture\n",
    "print(model)\n",
    "\n",
    "# start training\n",
    "train(model, sub_g, adj, sub_labels)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b9bc4fd2-4f5c-4998-8812-5b267e3e0aea",
   "metadata": {
    "id": "b9bc4fd2-4f5c-4998-8812-5b267e3e0aea",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "adj=sub_g.adj().to_dense()\n",
    "adj=adj+torch.eye(sub_g.adj().shape[0])\n",
    "deg=adj.sum(dim=0)\n",
    "adj=adj/deg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6932801-2f69-4077-9253-6c7459e49d0e",
   "metadata": {
    "id": "d6932801-2f69-4077-9253-6c7459e49d0e"
   },
   "source": [
    "单击 ... 即可显示**解决方案**。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fece35ff-373d-4cc1-9fc7-a2324f12e793",
   "metadata": {
    "id": "fece35ff-373d-4cc1-9fc7-a2324f12e793"
   },
   "source": [
    "<a name='s1-4.3'></a>\n",
    "### 图卷积网络 (GCN) ###\n",
    "正如 Kipf 和 Welling ([arXiv](https://arxiv.org/abs/1609.02907)) 指出的那样，常被引用的节点分类图卷积网络 (GCN) 在更新规则中使用对称归一化的方法。它涉及将可学习的函数两端乘以度数矩阵的平方根的倒数，这相当于除以节点的邻域大小和相邻节点的邻域大小的乘积的平方根。\n",
    "\n",
    "<p><img src='images/gcn.PNG' width=240></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fded42-faf7-4c86-8c7d-f8db2716a012",
   "metadata": {
    "id": "97fded42-faf7-4c86-8c7d-f8db2716a012"
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# create adjacency matrix\n",
    "adj=sub_g.adj().to_dense()\n",
    "\n",
    "# modify the adjacency matrix by adding the identity matrix to ensure nodes consider their own features\n",
    "adj=adj+torch.eye(sub_g.adj().shape[0])\n",
    "\n",
    "# get node degrees\n",
    "deg=adj.sum(dim=0)\n",
    "\n",
    "# normalization computes 1 over the square root of the degree matrix\n",
    "# multiply that on both sides with the adjacency matrix\n",
    "norm_deg=torch.diag(1.0/torch.sqrt(deg))\n",
    "# get the normalized adjacency matrix by multiplying the normalized degree matrix with \n",
    "# the product of the adjacency matrix and the normalized degree matrix\n",
    "norm_adj=torch.mm(norm_deg, torch.matmul(adj, norm_deg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1454bbbc-59ae-4c78-b3d3-9de58f8e737e",
   "metadata": {
    "id": "1454bbbc-59ae-4c78-b3d3-9de58f8e737e",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# instantiate simple model\n",
    "model=SimpleGraphNet(sub_g.ndata['feat'].shape[1], 32, num_classes)\n",
    "\n",
    "# print model architecture\n",
    "print(model)\n",
    "\n",
    "# start training\n",
    "train(model, sub_g, norm_adj, sub_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbee6070-1912-4de2-8f63-b80203772212",
   "metadata": {
    "id": "cbee6070-1912-4de2-8f63-b80203772212"
   },
   "source": [
    "<a name='s1-5'></a>\n",
    "## 使用 DGL 内置模组构建 GNN ##\n",
    "DGL 提供了许多热门 GNN 层的实现。它们都可以用一行代码轻松调用。如需查看受支持的图卷积模组的完整列表，请单击[此处](https://docs.dgl.ai/api/python/nn-pytorch.html)。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e33d77-2569-43a7-93f9-dc3cc5016884",
   "metadata": {
    "id": "04e33d77-2569-43a7-93f9-dc3cc5016884"
   },
   "source": [
    "<a name='s1-5.1'></a>\n",
    "### GraphConv ###\n",
    "接下来，我们将使用 DGL 中的 [GraphConv](https://docs.dgl.ai/en/0.9.x/generated/dgl.nn.pytorch.conv.GraphConv.html) 模组实现一个 3 层 GCN，该 GCN 能像上文一样利用均值归一化。通过堆叠 `N个` GCN 层，特征表示会更新节点信息，至高可达 `N` 跳。N 通常被视为模型调优的超参数。\n",
    "\n",
    "_注意：对于现在这种简单的方法，我们只需使用 `GraphConv` 中的 `in_feats`、`out_feats` 和 `norm` 参数。此外，所有 3 层都使用相同长度的 `h_feat` 隐藏状态向量。对于 `norm` 参数，我们可以使用 `right` 将聚合信息除以每个节点的入度，这相当对所接收的信息进行平均。或者，如果不应用归一化，我们可以使用 `none`；如果使用对称归一化扩展信息，则使用 `both`（默认）。_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c550a43-1654-4891-b2e0-773001061256",
   "metadata": {
    "id": "7c550a43-1654-4891-b2e0-773001061256"
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# import dependencies\n",
    "from dgl.nn import GraphConv\n",
    "\n",
    "# define GCN model\n",
    "class BuiltinGCN(nn.Module):\n",
    "    \"\"\"Graph convolutional network using DGL supported graph convolution modules\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    in_feats (int): input feature size\n",
    "    h_feats (int): hidden feature size\n",
    "    num_classes (int): number of classes\n",
    "    \"\"\"\n",
    "    def __init__(self, in_feat, h_feat, num_classes):\n",
    "        super(BuiltinGCN, self).__init__()\n",
    "        self.layer1=GraphConv(in_feat, h_feat, norm='right')\n",
    "        self.layer2=GraphConv(h_feat, h_feat, norm='right')\n",
    "        self.layer3=GraphConv(h_feat, num_classes, norm='right')\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        \"\"\"Forward computation\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        g (DGLGraph): the input graph\n",
    "        features (Tensor): the input node features\n",
    "        \"\"\"\n",
    "        h=self.layer1(g, h)\n",
    "        h=F.relu(h)\n",
    "        h=self.layer2(g, h)\n",
    "        h=F.relu(h)\n",
    "        h=self.layer3(g, h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7e3f14-3a73-4f9f-a4c2-87642b816b2b",
   "metadata": {
    "id": "6d7e3f14-3a73-4f9f-a4c2-87642b816b2b"
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# import dependencies\n",
    "import time\n",
    "\n",
    "# define evaluate\n",
    "def evaluate(model, g, labels, mask):\n",
    "    \"\"\"Model evaluation for particular set\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model (nn.Module): the model\n",
    "    g (DGLGraph): the input graph\n",
    "    labels (Tensor): the ground truth labels\n",
    "    mask (Tensor): the mask for a specific subset\n",
    "    \"\"\"\n",
    "    # assign features\n",
    "    features=g.ndata['feat']\n",
    "    \n",
    "    # set to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # put features through model to obtain logits \n",
    "        logits=model(g, features)\n",
    "        \n",
    "        # get logits and labels for particular set\n",
    "        logits=logits[mask]\n",
    "        labels=labels[mask]\n",
    "        \n",
    "        # get most likely class and count the number of corrects\n",
    "        _, indices = torch.max(logits, dim=1)\n",
    "        correct = torch.sum(indices == labels)\n",
    "        \n",
    "        # return accuracy\n",
    "        return correct.item() * 1.0 / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789c5cf1-852c-4240-acdf-bf4e6afb542b",
   "metadata": {
    "id": "789c5cf1-852c-4240-acdf-bf4e6afb542b"
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# define train\n",
    "def train(model, g, labels):\n",
    "    \"\"\"Model training\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model (nn.Module): the model\n",
    "    features (Tensor): the feature tensor\n",
    "    labels (Tensor): the ground truth labels\n",
    "    \"\"\"\n",
    "    # assign features\n",
    "    features=g.ndata['feat']\n",
    "    \n",
    "    # use a standard optimization pipeline using the adam optimizer\n",
    "    optimizer=torch.optim.Adam(model.parameters(), lr=0.02)\n",
    "\n",
    "    # standard training pipeline with early stopping\n",
    "    best_acc=0.0\n",
    "    for epoch in range(200): \n",
    "        start=time.time()\n",
    "\n",
    "        # set to training mode\n",
    "        model.train()\n",
    "        \n",
    "        # forward step\n",
    "        # calculate logits and loss\n",
    "        logits=model(g, features)\n",
    "        # calculate loss using log_softmax and negative log likelihood\n",
    "        logp=F.log_softmax(logits, 1)\n",
    "        loss=F.nll_loss(logp[train_mask], labels[train_mask])\n",
    "\n",
    "        # backward step\n",
    "        # zero out gradients before accumulating the gradients on backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # apply the optimizer to the gradients\n",
    "        optimizer.step()\n",
    "        \n",
    "        # evaluate on validation and test sets\n",
    "        val_acc=evaluate(model, g, labels, valid_mask)\n",
    "        test_acc=evaluate(model, g, labels, test_mask)\n",
    "        \n",
    "        # compare validation accuracy with best accuracy at 10 epoch intervals, which will update if exceeded\n",
    "        if (epoch%10==0) & (val_acc>best_acc):\n",
    "            best_acc=val_acc\n",
    "            print(\"Epoch {:03d} | Loss {:.4f} | Validation Acc {:.4f} | Test Acc {:.4f} | Time(s) {:.4f}\".format(\n",
    "                epoch, loss.item(), val_acc, test_acc, time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23840621-a0b8-4ec0-ab08-a0f0bc3cd184",
   "metadata": {
    "id": "23840621-a0b8-4ec0-ab08-a0f0bc3cd184",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "# instantiate GNN model using built-in GraphConv layers\n",
    "model=BuiltinGCN(sub_g.ndata['feat'].shape[1], 32, len(labels.unique()))\n",
    "\n",
    "# add self-loop to ensure nodes consider their own features\n",
    "sub_g=dgl.add_self_loop(sub_g)\n",
    "\n",
    "# print model architecture\n",
    "print(model)\n",
    "\n",
    "# start training\n",
    "train(model, sub_g, sub_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4e0ef9-3825-4b61-9fb8-55416dd62627",
   "metadata": {
    "id": "3e4e0ef9-3825-4b61-9fb8-55416dd62627"
   },
   "source": [
    "**非常棒！**您已顺利完成培训。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd47e4a7-0661-4d6b-93cc-372f44babba2",
   "metadata": {
    "id": "bd47e4a7-0661-4d6b-93cc-372f44babba2"
   },
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
